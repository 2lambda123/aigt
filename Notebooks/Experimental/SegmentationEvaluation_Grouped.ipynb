{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import scipy.ndimage\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import evaluation_metrics\n",
    "\n",
    "# Updating these names to reflect the location of your data.\n",
    "notebook_fullpath = r\"c:\\Data\\LeaveOneOutNotebooks\"\n",
    "\n",
    "# Update this to change the file prefix of the saved HTML file.\n",
    "notebook_name = \"SegmentationEvaluation_Grouped\"\n",
    "\n",
    "acceptable_margin_mm = 1\n",
    "mm_per_pixel = 1\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001,\n",
    "                  0.0008, 0.0006, 0.0004, 0.0002, 0.0001,\n",
    "                  0.00001, 0.000001]\n",
    "\n",
    "# Change these to match your file prefixes\n",
    "outList = [r\"q000\", r\"q001\", r\"q002\", r\"q003\", r\"q004\", r\"q005\", r\"q006\", r\"q007\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(groundtruth_fullname, prediction_fullname):\n",
    "    groundtruth_data = np.load(groundtruth_fullname)\n",
    "    prediction_data = np.load(prediction_fullname)\n",
    "\n",
    "    num_groundtruth = groundtruth_data.shape[0]\n",
    "    num_prediction = prediction_data.shape[0]\n",
    "\n",
    "    print(\"Found {} ground truth images and {} predictions\\n\".format(num_groundtruth, num_prediction))\n",
    "\n",
    "    if num_groundtruth != num_prediction:\n",
    "        print(\"Number of images should be equal!\")\n",
    "        raise\n",
    "    \n",
    "    return groundtruth_data, prediction_data, num_groundtruth, num_prediction\n",
    "\n",
    "def dilate_stack(segmentation_data, iterations):\n",
    "    \n",
    "    return np.array([scipy.ndimage.binary_dilation(y, iterations=iterations) for y in segmentation_data])\n",
    "\n",
    "def dilate_ground(groundtruth_data, acceptable_margin_mm, mm_per_pixel):\n",
    "    acceptable_margin_pixel = int(acceptable_margin_mm / mm_per_pixel)\n",
    "    acceptable_region = dilate_stack(groundtruth_data[:, :, :, 0], acceptable_margin_pixel)\n",
    "    \n",
    "    return acceptable_region\n",
    "\n",
    "def compute_regions(groundtruth_data, prediction_data, acceptable_region):\n",
    "    true_pos_prediction = np.minimum(groundtruth_data[:,:,:,0], prediction_data[:,:,:,1])\n",
    "    not_acceptable_region = 1 - acceptable_region\n",
    "    false_pos_prediction = np.minimum(not_acceptable_region, prediction_data[:, :, :, 1])\n",
    "    \n",
    "    return true_pos_prediction, false_pos_prediction, not_acceptable_region\n",
    "\n",
    "def compute_prediction_amounts(groundtruth_data, not_acceptable_region, true_pos_prediction, false_pos_prediction):\n",
    "    fpp = np.sum(false_pos_prediction[:,:,:])\n",
    "    tna = np.sum(not_acceptable_region[:,:,:])\n",
    "    tpp = np.sum(true_pos_prediction)\n",
    "    tpa = np.sum(groundtruth_data[:,:,:,0])\n",
    "\n",
    "    print(\"Total false positive prediction amount per image: {:.2f}\".format(fpp / num_groundtruth))\n",
    "    print(\"Total true negative area per image:               {:.2f}\".format(tna / num_groundtruth))\n",
    "    print(\"  {:.2f}% of the true negative area was correctly predicted\".format((tna - fpp) / tna * 100))\n",
    "    print(\"\")\n",
    "    print(\"Total true positive prediction amount per image: {:.2f}\".format(tpp / num_groundtruth))\n",
    "    print(\"Total true positive area per image:              {:.2f}\".format(tpa / num_groundtruth))\n",
    "    print(\"  {:.2f}% of the true positive area was correctly predicted\\n\".format(tpp / tpa * 100))\n",
    "\n",
    "def compute_roc(roc_thresholds, prediction_data, groundtruth_data, acceptable_margin_mm, mm_per_pixel):\n",
    "    false_positives = np.zeros(len(roc_thresholds))\n",
    "    true_positives = np.zeros(len(roc_thresholds))\n",
    "\n",
    "    for i in range(len(roc_thresholds)):\n",
    "        threshold = roc_thresholds[i]\n",
    "        prediction_thresholded = np.copy(prediction_data)\n",
    "        prediction_thresholded[prediction_thresholded >= threshold] = 1.0\n",
    "        prediction_thresholded[prediction_thresholded < threshold] = 0.0\n",
    "        metrics = evaluation_metrics.compute_evaluation_metrics(\n",
    "            prediction_thresholded, groundtruth_data, acceptable_margin_mm=acceptable_margin_mm, mm_per_pixel=mm_per_pixel)\n",
    "        true_negative_area_perc = metrics[evaluation_metrics.TRUE_NEGATIVE_AREA_PERCENT]\n",
    "        false_positives[i] = (100 - true_negative_area_perc) / 100.0\n",
    "        true_positives[i] = metrics[evaluation_metrics.TRUE_POSITIVE_AREA_PERCENT] / 100.0\n",
    "    \n",
    "    return true_positives, false_positives\n",
    "\n",
    "# Goodness is defined as distance from the diagonal of the ROC curve\n",
    "def compute_goodness(roc_thresholds, true_positives, false_positives):\n",
    "    goodnesses = np.zeros(len(roc_thresholds))\n",
    "    for i in range(len(roc_thresholds)):\n",
    "        crossprod = np.cross((1.0, 1.0), (false_positives[i], true_positives[i]))\n",
    "        goodnesses[i] = np.linalg.norm(crossprod)/np.linalg.norm([1.0, 1.0])\n",
    "\n",
    "    best_threshold_index = np.argmax(goodnesses)\n",
    "    print(\"Best threshold:           {}\".format(roc_thresholds[best_threshold_index]))\n",
    "    print(\"Best true positive rate:  {}\".format(true_positives[best_threshold_index]))\n",
    "    print(\"Best false positive rate: {}\\n\".format(false_positives[best_threshold_index]))\n",
    "\n",
    "def compute_AUC(true_positives, false_positives):\n",
    "    area = 0.0\n",
    "\n",
    "    fps = np.zeros(len(false_positives) * 2)\n",
    "    tps = np.zeros(len(false_positives) * 2)\n",
    "\n",
    "    for i in range(len(false_positives)):\n",
    "        fps[i*2] = false_positives[i]\n",
    "        tps[i*2] = true_positives[i]\n",
    "        if i == len(false_positives) - 1:\n",
    "            fps[i*2+1] = 1.0\n",
    "            tps[i*2+1] = true_positives[i]\n",
    "            area = area + (1.0 - false_positives[i]) * true_positives[i]\n",
    "        else:\n",
    "            fps[i*2+1] = false_positives[i+1]\n",
    "            tps[i*2+1] = true_positives[i]\n",
    "            area = area + (false_positives[i+1] - false_positives[i]) * true_positives[i]\n",
    "\n",
    "    print(\"AUC = {}\\n\".format(area))\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Assessing Predictions on model that left out q000\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 148.12\n",
      "Total true negative area per image:               16310.87\n",
      "  99.09% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 25.14\n",
      "Total true positive area per image:              35.72\n",
      "  70.37% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.008\n",
      "Best true positive rate:  0.9537861084870481\n",
      "Best false positive rate: 0.04736027816549509\n",
      "\n",
      "AUC = 0.9876833418562411\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q001\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 120.54\n",
      "Total true negative area per image:               16310.87\n",
      "  99.26% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 23.77\n",
      "Total true positive area per image:              35.72\n",
      "  66.53% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.006\n",
      "Best true positive rate:  0.9650972008153932\n",
      "Best false positive rate: 0.04843966134243928\n",
      "\n",
      "AUC = 0.9892396067875615\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q002\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 147.59\n",
      "Total true negative area per image:               16310.87\n",
      "  99.10% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 22.72\n",
      "Total true positive area per image:              35.72\n",
      "  63.61% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.006\n",
      "Best true positive rate:  0.9523691145030577\n",
      "Best false positive rate: 0.06161141388905449\n",
      "\n",
      "AUC = 0.9839228950452771\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q003\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 208.28\n",
      "Total true negative area per image:               16310.87\n",
      "  98.72% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 28.73\n",
      "Total true positive area per image:              35.72\n",
      "  80.42% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.04\n",
      "Best true positive rate:  0.9795157360910853\n",
      "Best false positive rate: 0.03783944774174301\n",
      "\n",
      "AUC = 0.9930186126993747\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q004\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 157.84\n",
      "Total true negative area per image:               16310.87\n",
      "  99.03% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 26.49\n",
      "Total true positive area per image:              35.72\n",
      "  74.14% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.008\n",
      "Best true positive rate:  0.9668125093223289\n",
      "Best false positive rate: 0.05237959506251883\n",
      "\n",
      "AUC = 0.9902135393011051\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q005\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 115.41\n",
      "Total true negative area per image:               16310.87\n",
      "  99.29% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 21.61\n",
      "Total true positive area per image:              35.72\n",
      "  60.48% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.004\n",
      "Best true positive rate:  0.9500074578630736\n",
      "Best false positive rate: 0.05664267946637395\n",
      "\n",
      "AUC = 0.9842974328988671\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q006\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 87.68\n",
      "Total true negative area per image:               16310.87\n",
      "  99.46% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 19.43\n",
      "Total true positive area per image:              35.72\n",
      "  54.39% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.004\n",
      "Best true positive rate:  0.9690001491572615\n",
      "Best false positive rate: 0.05187093900728229\n",
      "\n",
      "AUC = 0.9889242746168265\n",
      "\n",
      "#######################################################\n",
      "Assessing Predictions on model that left out q007\n",
      "#######################################################\n",
      "\n",
      "Found 1126 ground truth images and 1126 predictions\n",
      "\n",
      "Total false positive prediction amount per image: 98.64\n",
      "Total true negative area per image:               16310.87\n",
      "  99.40% of the true negative area was correctly predicted\n",
      "\n",
      "Total true positive prediction amount per image: 21.88\n",
      "Total true positive area per image:              35.72\n",
      "  61.24% of the true positive area was correctly predicted\n",
      "\n",
      "Best threshold:           0.004\n",
      "Best true positive rate:  0.9582111072440711\n",
      "Best false positive rate: 0.052228555467440145\n",
      "\n",
      "AUC = 0.9867217249613288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This runs the bulk of the computation of metrics.\n",
    "for out in outList:\n",
    "    \n",
    "    print(\"#######################################################\")\n",
    "    print(\"Assessing Predictions on model that left out\", out)\n",
    "    print(\"#######################################################\\n\")\n",
    "\n",
    "    # Use these for the Leave One Out Data Set.\n",
    "    #groundtruth_fullname = r\"c:\\Data\\LeaveOneOutTestArrays\\\\\" + out + r\"_segmentation.npy\"\n",
    "    #prediction_fullname=r\"c:\\Data\\LeaveOneOutTestArrays\\\\\" + out + r\"_prediction.npy\"\n",
    "\n",
    "    # Use these for the Children's Data Set.\n",
    "    groundtruth_fullname = r\"c:\\Data\\ChildrensTestArrays\\segmentation-test.npy\"\n",
    "    prediction_fullname=r\"c:\\Data\\ChildrensTestArrays\\\\\" + out + r\"_prediction.npy\"\n",
    "\n",
    "    # Get Data.\n",
    "    groundtruth_data, prediction_data, num_groundtruth, num_prediction = read_data(groundtruth_fullname, prediction_fullname)\n",
    "    # Dilate Data.\n",
    "    acceptable_region = dilate_ground(groundtruth_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    true_pos_prediction, false_pos_prediction, not_acceptable_region = compute_regions(groundtruth_data, prediction_data, acceptable_region)\n",
    "    # Compute Predictive Metrics.\n",
    "    compute_prediction_amounts(groundtruth_data, not_acceptable_region, true_pos_prediction, false_pos_prediction)\n",
    "    # Compute ROC Curve Data.\n",
    "    true_positives, false_positives = compute_roc(roc_thresholds, prediction_data, groundtruth_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    # Compute Goodness.\n",
    "    compute_goodness(roc_thresholds, true_positives, false_positives)\n",
    "    # Compute AUC.\n",
    "    area = compute_AUC(true_positives, false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: c:\\Data\\LeaveOneOutNotebooks\\SegmentationEvaluation_Grouped_2019-10-11_08-28-50.html\n"
     ]
    }
   ],
   "source": [
    "# Archive notebook with unique filenames based on timestamps in one single HTML file.\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "if not os.path.exists(notebook_fullpath):\n",
    "    os.makedirs(notebook_fullpath)\n",
    "    print(\"Creating folder: {}\".format(notebook_fullpath))\n",
    "notebook_file_name = notebook_name + \"_\" + timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebook_fullpath, notebook_file_name)\n",
    "os.system(\"jupyter nbconvert --to html \"+ notebook_name +\" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
