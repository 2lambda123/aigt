{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 24 ultrasound images and 24 segmentations\n"
     ]
    }
   ],
   "source": [
    "ultrasound_fullname = 'numpy_data/Stacked Arrays/Training/stacked_image_array.npy'\n",
    "segmentation_fullname = 'numpy_data/Stacked Arrays/Training/stacked_segmentation_array.npy'\n",
    "\n",
    "ultrasound_data = np.load(ultrasound_fullname)\n",
    "segmentation_data = np.load(segmentation_fullname)\n",
    "\n",
    "num_ultrasound = ultrasound_data.shape[0]\n",
    "num_segmentation = segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} ultrasound images and {} segmentations\".format(num_ultrasound, num_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test ultrasound from: numpy_data/Stacked Arrays/Test/test_image_array.npy\n",
      "Reading test segmentation from : numpy_data/Stacked Arrays/Test/test_segmentation_array.npy\n",
      "\n",
      "Found 6 test ultrasound images and 6 segmentations\n"
     ]
    }
   ],
   "source": [
    "test_ultrasound_fullname = 'numpy_data/Stacked Arrays/Test/test_image_array.npy'\n",
    "test_segmentation_fullname = 'numpy_data/Stacked Arrays/Test/test_segmentation_array.npy'\n",
    "\n",
    "print(\"Reading test ultrasound from: {}\".format(test_ultrasound_fullname))\n",
    "print(\"Reading test segmentation from : {}\".format(test_segmentation_fullname))\n",
    "\n",
    "test_ultrasound_data = np.load(test_ultrasound_fullname)\n",
    "test_segmentation_data = np.load(test_segmentation_fullname)\n",
    "\n",
    "num_test_ultrasound = test_ultrasound_data.shape[0]\n",
    "num_test_segmentation = test_segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} test ultrasound images and {} segmentations\".format(num_test_ultrasound, num_test_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator\n",
    "\n",
    "import keras.utils\n",
    "import scipy.ndimage\n",
    "\n",
    "max_rotation_angle = 10\n",
    "max_shift = 0.2\n",
    "max_zoom = 0.2\n",
    "\n",
    "class UltrasoundSegmentationBatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 image_dimensions=(128, 128, 128),\n",
    "                 shuffle=True,\n",
    "                 n_channels=1,\n",
    "                 n_classes=2):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.number_of_images = self.x.shape[0]\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.number_of_images / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        x = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.image_dimensions))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            flip_flag = np.random.randint(2)\n",
    "            x[i,:,:,:,:] = np.flip(self.x[batch_indexes[i],:,:,:,:])\n",
    "            y[i,:,:,:]= np.flip(self.y[batch_indexes[i],:,:,:])\n",
    "            \n",
    "        angle_x = np.random.randint(-max_rotation_angle, max_rotation_angle)\n",
    "        # rotate x-axis\n",
    "        x_rot = scipy.ndimage.interpolation.rotate(x, angle_x, (1,2), False, mode=\"constant\", cval=0, order=0)\n",
    "        y_rot = scipy.ndimage.interpolation.rotate(y, angle_x, (1,2), False, mode=\"constant\", cval=0, order=0)\n",
    "        \n",
    "        angle_y = np.random.randint(-max_rotation_angle, max_rotation_angle)\n",
    "        #rotate y-axis\n",
    "        x_rot = scipy.ndimage.interpolation.rotate(x, angle_y, (0,2), False, mode=\"constant\", cval=0, order=0)\n",
    "        y_rot = scipy.ndimage.interpolation.rotate(y, angle_y, (0,2), False, mode=\"constant\", cval=0, order=0)\n",
    "        \n",
    "        angle_z = np.random.randint(-max_rotation_angle, max_rotation_angle)\n",
    "        #rotate z-axis\n",
    "        x_rot = scipy.ndimage.interpolation.rotate(x, angle_z, (0,1), False, mode=\"constant\", cval=0, order=0)\n",
    "        y_rot = scipy.ndimage.interpolation.rotate(y, angle_z, (0,1), False, mode=\"constant\", cval=0, order=0)\n",
    "\n",
    "        \n",
    "        #shift = np.random.uniform(-max_shift, max_shift)\n",
    "        #x_shift = scipy.ndimage.interpolation.shift(x_rot, shift)\n",
    "        #y_shift = scipy.ndimage.interpolation.shift(y_rot, shift)\n",
    "        \n",
    "        # zoom = np.random.uniform(-max_zoom, max_zoom)\n",
    "        # x_zoom = scipy.ndimage.interpolation.zoom(x_shift, zoom)\n",
    "        # y_zoom = scipy.ndimage.interpolation.zoom(y_shift, zoom)\n",
    "    \n",
    "        x_aug = np.clip(x_rot, 0.0, 1.0)\n",
    "        y_aug = np.clip(y_rot, 0.0, 1.0)\n",
    "        \n",
    "        y_onehot = keras.utils.to_categorical(y_aug, self.n_classes)\n",
    "\n",
    "        return x_aug, y_onehot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dilated output\n",
    "\n",
    "def dilateStack(segmentation_data, iterations):\n",
    "    return np.array([scipy.ndimage.binary_dilation(y, iterations=iterations) for y in segmentation_data])\n",
    "\n",
    "width = 2\n",
    "segmentation_dilated = dilateStack(segmentation_data[:, :, :, :, 0], width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you don't want dilation\n",
    "\n",
    "segmentation_dilated[:, :, :, :] = segmentation_data[:, :, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\huyiy\\Anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"batch_normalization_1/cond/Merge:0\", shape=(?, 2, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_2/cond/Merge:0\", shape=(?, 4, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_3/cond/Merge:0\", shape=(?, 8, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_4/cond/Merge:0\", shape=(?, 16, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_5/cond/Merge:0\", shape=(?, 32, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"batch_normalization_6/cond/Merge:0\", shape=(?, 64, 64, 64, 8), dtype=float32)\n",
      "Tensor(\"conv3d_14/truediv:0\", shape=(?, 128, 128, 128, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "def nvidia_unet(patch_size=128, num_classes=num_classes):\n",
    "    input_ = Input((128, 128, 128, 1))\n",
    "    skips = []\n",
    "    output = input_\n",
    "    c = num_classes\n",
    "    \n",
    "    for shape, filters in zip([5, 3, 3, 3, 3, 3, 3], [8, 16, 32, 32, 32, 32, 32]):\n",
    "        skips.append(output)\n",
    "        #print(\"pre_skip\")\n",
    "        #print(output)\n",
    "        #print(shape)\n",
    "        output= Conv3D(filters, (3, 3, 3), strides=2, padding=\"same\", activation=\"relu\")(output)\n",
    "        #print(\"output3d\")\n",
    "        #print(output)\n",
    "    \n",
    "    # output = keras.layers.UpSampling3D(size=(1, 2, 2))(output)\n",
    "    for shape, filters in zip([4, 4, 4, 4, 4, 4, 4], [32, 32, 32, 32, 16, 8, 2]):\n",
    "        #print(output.shape)\n",
    "        output = keras.layers.UpSampling3D()(output)\n",
    "        #print(\"output2.0:\")\n",
    "        #print(output)\n",
    "        skip_output = skips.pop()\n",
    "        output = concatenate([output, skip_output], axis=4)\n",
    "\n",
    "        if filters != c:\n",
    "            activation = \"relu\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        output = Conv3D(filters, (3, 3, 3), activation=activation, padding=\"same\")(output)\n",
    "        if filters != c:\n",
    "            output = BatchNormalization(momentum=.9)(output)\n",
    "        \n",
    "        print(output)\n",
    "    \n",
    "    assert len(skips) == 0\n",
    "    return Model([input_], [output])\n",
    "\n",
    "model = nvidia_unet(128, num_classes)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 376624 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Model built with {} parameters\".format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate decay = 0.0003996\n"
     ]
    }
   ],
   "source": [
    "max_learning_rate = 0.01\n",
    "min_learning_rate = 0.00001\n",
    "num_epochs = 25\n",
    "\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "               loss= \"binary_crossentropy\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Learning rate decay = {}\".format(learning_rate_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\huyiy\\Anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\huyiy\\Anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.6101 - acc: 0.7386 - val_loss: 3.5104 - val_acc: 0.2870\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 29s 4s/step - loss: 0.4036 - acc: 0.9305 - val_loss: 0.8330 - val_acc: 0.7697\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.1954 - acc: 0.9858 - val_loss: 0.2211 - val_acc: 0.9486\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 28s 4s/step - loss: 0.0861 - acc: 0.9913 - val_loss: 0.0389 - val_acc: 0.9981\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.0339 - acc: 0.9965 - val_loss: 0.0228 - val_acc: 0.9970\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.0160 - acc: 0.9978 - val_loss: 0.0461 - val_acc: 0.9942\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.0150 - acc: 0.9978 - val_loss: 0.1063 - val_acc: 0.9661\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.0151 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9950\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.0276 - acc: 0.9958 - val_loss: 0.0456 - val_acc: 0.9969\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.0370 - acc: 0.9964 - val_loss: 0.0250 - val_acc: 0.9983\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.0216 - acc: 0.9969 - val_loss: 0.0121 - val_acc: 0.9983\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 36s 5s/step - loss: 0.0187 - acc: 0.9973 - val_loss: 0.0128 - val_acc: 0.9986\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 46s 6s/step - loss: 0.0142 - acc: 0.9978 - val_loss: 0.0292 - val_acc: 0.9952\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.0199 - acc: 0.9966 - val_loss: 0.0107 - val_acc: 0.9982\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 32s 4s/step - loss: 0.0123 - acc: 0.9979 - val_loss: 0.0196 - val_acc: 0.9963\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.0138 - acc: 0.9977 - val_loss: 0.0094 - val_acc: 0.9982\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.0178 - acc: 0.9973 - val_loss: 0.0299 - val_acc: 0.9961\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.0152 - acc: 0.9979 - val_loss: 0.0164 - val_acc: 0.9972\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.0150 - acc: 0.9977 - val_loss: 0.0153 - val_acc: 0.9971\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 32s 4s/step - loss: 0.0132 - acc: 0.9977 - val_loss: 0.0169 - val_acc: 0.9970\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.0108 - acc: 0.9980 - val_loss: 0.0143 - val_acc: 0.9971\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.0153 - acc: 0.9971 - val_loss: 0.0162 - val_acc: 0.9974\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.0144 - acc: 0.9975 - val_loss: 0.0165 - val_acc: 0.9967\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.0181 - acc: 0.9968 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.0153 - acc: 0.9973 - val_loss: 0.0170 - val_acc: 0.9969\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "training_generator = UltrasoundSegmentationBatchGenerator(ultrasound_data, segmentation_data[:, :, :, :, 0], batch_size)\n",
    "test_generator = UltrasoundSegmentationBatchGenerator(test_ultrasound_data, test_segmentation_data[:, :, :, :, 0], batch_size)\n",
    "\n",
    "training_time_start = datetime.datetime.now()\n",
    "\n",
    "training_log = model.fit_generator(training_generator,\n",
    "                                   validation_data=test_generator,\n",
    "                                   epochs=num_epochs,\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_stop = datetime.datetime.now()\n",
    "print(\"Training started at: {}\".format(training_time_start))\n",
    "print(\"Training stopped at: {}\".format(training_time_stop))\n",
    "print(\"Total training time: {}\".format(training_time_stop-training_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "saved_models_folder = 'saved_models'\n",
    "model_file_name = \"model_\" + timestamp + \".h5\"\n",
    "weights_file_path = os.path.join(saved_models_folder, model_file_name)\n",
    "\n",
    "model.save(weights_file_path)\n",
    "print(\"Model saved to: {}\".format(weights_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model('saved_models\\model_2019-07-24_16-47-12.h5')\n",
    "# print(weights_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(test_ultrasound_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training loss and accuracy curves over epochs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_log.history['loss'], 'bo--')\n",
    "plt.plot(training_log.history['val_loss'], 'ro-')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs (n)')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_log.history['acc'], 'bo--')\n",
    "plt.plot(training_log.history['val_acc'], 'ro-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs (n)')\n",
    "plt.legend(['Training accuracy', 'Validation accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-slice view code extracted and adapted from: https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0] // 2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index + 1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def remove_keymap_conflicts(new_keys_set):\n",
    "    for prop in plt.rcParams:\n",
    "        if prop.startswith('keymap.'):\n",
    "            keys = plt.rcParams[prop]\n",
    "            remove_list = set(keys) & new_keys_set\n",
    "            for key in remove_list:\n",
    "                keys.remove(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ultrasound\n",
    "ultrasound_img = test_ultrasound_data[0]\n",
    "print(ultrasound_img.shape)\n",
    "multi_slice_viewer(ultrasound_img[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "segmentation_img = test_segmentation_data[0]\n",
    "print(segmentation_img.shape)\n",
    "multi_slice_viewer(segmentation_img[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted_img = y_pred[0]\n",
    "print(predicted_img.shape)\n",
    "multi_slice_viewer(predicted_img[:, :, :, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
