{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this notebook\n",
    "The data used in this notebook is not public. Contact Tamas to get an API key. Then create a python file in the same folder as this notebook, and name that file *girder_apikey_read.py*. Add only one line to that file that looks like this, just a different key string:\n",
    "`girder_apikey_read=\"UjNzqutrfBwuk4t39VlJnJs4t3EZ6i7\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-01-13_15-08-48\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"BreastTumorSegmentationStudy\"\n",
    "\n",
    "# This should be the only parameter to update for your local environment\n",
    "\n",
    "local_data_folder = r\"c:\\Data\\BreastTumorSegmentationStudy\"\n",
    "#local_data_folder = r\"C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# For debugging only\n",
    "\n",
    "limit_validation_rounds = -1\n",
    "# limit_validation_rounds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import sagittal_spine_segmentation_unet as unet\n",
    "import evaluation_metrics\n",
    "'''\n",
    "\n",
    "from girder_apikey_read import girder_apikey_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5e1bae9ed9e6a3be02d013bc\", #003\n",
    "    \"5dfbc687d9e6a3be02d01343\", #004-v02\n",
    "    \"5e1cb476d9e6a3be02d01425\", #005-v02\n",
    "    \"5e1cb685d9e6a3be02d01434\", #006-v02\n",
    "    \"5e1cb84ed9e6a3be02d0143a\", #007-v02\n",
    "    \"5e14cef4d9e6a3be02d01377\", #008-v02\n",
    "    \"5e14cef4d9e6a3be02d0137a\", #009-v02\n",
    "    \"5e1cba04d9e6a3be02d01440\", #010-v02\n",
    "    \"5e1cbd21d9e6a3be02d01446\", #011\n",
    "    \"5e1cbf54d9e6a3be02d0144c\", #012\n",
    "    \"5e1cc395d9e6a3be02d01452\", #013\n",
    "    \"5e1cc4fcd9e6a3be02d01458\", #014\n",
    "    \"5e14cef4d9e6a3be02d0137d\", #015\n",
    "    \"5e1cc907d9e6a3be02d0145e\", #016\n",
    "    \"5e1cca85d9e6a3be02d01464\", #018\n",
    "    \"5e1ccb5dd9e6a3be02d0146a\", #019\n",
    "    \"5e1cb5ced9e6a3be02d0142b\", #020\n",
    "    \"5e16028cd9e6a3be02d01386\", #021\n",
    "    \"5e163f18d9e6a3be02d01392\", #022\n",
    "    \"5e163f0dd9e6a3be02d0138c\", #023\n",
    "    \"5e163f22d9e6a3be02d01398\", #024\n",
    "    \"5e163f2ad9e6a3be02d0139e\", #025\n",
    "    \"5e1c99f1d9e6a3be02d01401\", #026\n",
    "    \"5e1c99f1d9e6a3be02d01404\", #027\n",
    "    \"5e1c99f2d9e6a3be02d01407\", #028\n",
    "    \"5e1c99f2d9e6a3be02d0140a\", #029\n",
    "    \"5e1c99f3d9e6a3be02d0140d\", #030\n",
    "    \"5e1c99f3d9e6a3be02d01410\", #031\n",
    "    \"5e1c99f4d9e6a3be02d01413\", #032\n",
    "    \"5e1c99f5d9e6a3be02d01416\", #035\n",
    "    \"5e1c99f5d9e6a3be02d01419\", #037\n",
    "    \"5e1c99f6d9e6a3be02d0141c\", #038\n",
    "    \"5e1c99f6d9e6a3be02d0141f\", #039\n",
    "    \"5df79d49d9e6a3be02d01332\", #test\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"ultrasound-003-v02.npy\",\n",
    "    \"ultrasound-004-v02.npy\",\n",
    "    \"ultrasound-005-v02.npy\",\n",
    "    \"ultrasound-006-v02.npy\",\n",
    "    \"ultrasound-007-v02.npy\",\n",
    "    \"ultrasound-008-v02.npy\",\n",
    "    \"ultrasound-009-v02.npy\",\n",
    "    \"ultrasound-010-v02.npy\",\n",
    "    \"ultrasound-011.npy\",\n",
    "    \"ultrasound-012.npy\",\n",
    "    \"ultrasound-013.npy\",\n",
    "    \"ultrasound-014.npy\",\n",
    "    \"ultrasound-015.npy\",\n",
    "    \"ultrasound-016.npy\",\n",
    "    \"ultrasound-018.npy\",\n",
    "    \"ultrasound-019.npy\",\n",
    "    \"ultrasound-020.npy\",\n",
    "    \"ultrasound-021.npy\",\n",
    "    \"ultrasound-022.npy\",\n",
    "    \"ultrasound-023.npy\",\n",
    "    \"ultrasound-024.npy\",\n",
    "    \"ultrasound-025.npy\",\n",
    "    \"ultrasound-026.npy\",\n",
    "    \"ultrasound-027.npy\",\n",
    "    \"ultrasound-028.npy\",\n",
    "    \"ultrasound-029.npy\",\n",
    "    \"ultrasound-030.npy\",\n",
    "    \"ultrasound-031.npy\",\n",
    "    \"ultrasound-032.npy\",\n",
    "    \"ultrasound-035.npy\",\n",
    "    \"ultrasound-037.npy\",\n",
    "    \"ultrasound-038.npy\",\n",
    "    \"ultrasound-039.npy\",\n",
    "    \"ultrasound-test.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5e1bae9ed9e6a3be02d013b9\", #003\n",
    "    \"5dfbc686d9e6a3be02d01340\", #004-v02\n",
    "    \"5e1cb475d9e6a3be02d01422\", #005-v02\n",
    "    \"5e1cb684d9e6a3be02d01431\", #006-v02\n",
    "    \"5e1cb84dd9e6a3be02d01437\", #007-v02\n",
    "    \"5e14cef3d9e6a3be02d0136e\", #008-v02\n",
    "    \"5e14cef3d9e6a3be02d01371\", #009-v02\n",
    "    \"5e1cba04d9e6a3be02d0143d\", #010-v02\n",
    "    \"5e1cbd20d9e6a3be02d01443\", #011\n",
    "    \"5e1cbf54d9e6a3be02d01449\", #012\n",
    "    \"5e1cc395d9e6a3be02d0144f\", #013\n",
    "    \"5e1cc4fcd9e6a3be02d01455\", #014\n",
    "    \"5e14cef3d9e6a3be02d01374\", #015\n",
    "    \"5e1cc906d9e6a3be02d0145b\", #016\n",
    "    \"5e1cca84d9e6a3be02d01461\", #018\n",
    "    \"5e1ccb5cd9e6a3be02d01467\", #019\n",
    "    \"5e1cb5ced9e6a3be02d01428\", #020\n",
    "    \"5e16028bd9e6a3be02d01383\", #021\n",
    "    \"5e163f17d9e6a3be02d0138f\", #022\n",
    "    \"5e163f0cd9e6a3be02d01389\", #023\n",
    "    \"5e163f21d9e6a3be02d01395\", #024\n",
    "    \"5e163f29d9e6a3be02d0139b\", #025\n",
    "    \"5e1c99edd9e6a3be02d013e0\", #026\n",
    "    \"5e1c99edd9e6a3be02d013e3\", #027\n",
    "    \"5e1c99edd9e6a3be02d013e6\", #028\n",
    "    \"5e1c99eed9e6a3be02d013e9\", #029\n",
    "    \"5e1c99eed9e6a3be02d013ec\", #030\n",
    "    \"5e1c99eed9e6a3be02d013ef\", #031\n",
    "    \"5e1c99efd9e6a3be02d013f2\", #032\n",
    "    \"5e1c99efd9e6a3be02d013f5\", #035\n",
    "    \"5e1c99efd9e6a3be02d013f8\", #037\n",
    "    \"5e1c99efd9e6a3be02d013fb\", #038\n",
    "    \"5e1c99f0d9e6a3be02d013fe\", #039\n",
    "    \"5df79d41d9e6a3be02d0131a\", #test    \n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"segmentation-003-v02.npy\",\n",
    "    \"segmentation-004-v02.npy\",\n",
    "    \"segmentation-005-v02.npy\",\n",
    "    \"segmentation-006-v02.npy\",\n",
    "    \"segmentation-007-v02.npy\",\n",
    "    \"segmentation-008-v02.npy\",\n",
    "    \"segmentation-009-v02.npy\",\n",
    "    \"segmentation-010-v02.npy\",\n",
    "    \"segmentation-011.npy\",\n",
    "    \"segmentation-012.npy\",\n",
    "    \"segmentation-013.npy\",\n",
    "    \"segmentation-014.npy\",\n",
    "    \"segmentation-015.npy\",\n",
    "    \"segmentation-016.npy\",\n",
    "    \"segmentation-018.npy\",\n",
    "    \"segmentation-019.npy\",\n",
    "    \"segmentation-020.npy\",\n",
    "    \"segmentation-021.npy\",\n",
    "    \"segmentation-022.npy\",\n",
    "    \"segmentation-023.npy\",\n",
    "    \"segmentation-024.npy\",\n",
    "    \"segmentation-025.npy\",\n",
    "    \"segmentation-026.npy\",\n",
    "    \"segmentation-027.npy\",\n",
    "    \"segmentation-028.npy\",\n",
    "    \"segmentation-029.npy\",\n",
    "    \"segmentation-030.npy\",\n",
    "    \"segmentation-031.npy\",\n",
    "    \"segmentation-032.npy\",\n",
    "    \"segmentation-035.npy\",\n",
    "    \"segmentation-037.npy\",\n",
    "    \"segmentation-038.npy\",\n",
    "    \"segmentation-039.npy\",\n",
    "    \"segmentation-test.npy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "results_save_folder   = \"SavedResults\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "val_data_folder       = \"PredictionsValidation\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "results_save_fullpath = os.path.join(local_data_folder, results_save_folder)\n",
    "models_save_fullpath = os.path.join(local_data_folder, models_save_folder)\n",
    "val_data_fullpath = os.path.join(local_data_folder, val_data_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(results_save_fullpath):\n",
    "    os.makedirs(results_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(results_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_fullpath):\n",
    "    os.makedirs(models_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(models_save_fullpath))\n",
    "\n",
    "if not os.path.exists(val_data_fullpath):\n",
    "    os.makedirs(val_data_fullpath)\n",
    "    print(\"Created folder: {}\".format(val_data_fullpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f0ecaaaeb64c45b3d6b4c36e80d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=68)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\ultrasound-016.npy...\n",
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\segmentation-016.npy...\n",
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\ultrasound-018.npy...\n",
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\segmentation-018.npy...\n",
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\ultrasound-019.npy...\n",
      "Downloading C:\\Users\\jgerolami\\Documents\\GitHub\\aigt\\Notebooks\\Segmentation\\data\\DataArrays\\segmentation-019.npy...\n",
      "\n",
      "Total download time: 0:00:04.955693\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "# Setting up number of validation rounds\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "if limit_validation_rounds > 0:\n",
    "    num_validation_rounds = min(n_files, limit_validation_rounds)\n",
    "else:\n",
    "    num_validation_rounds = n_files\n",
    "\n",
    "# Preparing progress bar\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "# Downloading files\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "gclient.authenticate(apiKey=girder_apikey_read)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
