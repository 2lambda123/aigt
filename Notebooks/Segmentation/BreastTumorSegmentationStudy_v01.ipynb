{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this notebook\n",
    "The data used in this notebook is not public. Contact Tamas to get an API key. Then create a python file in the same folder as this notebook, and name that file *girder_apikey_read.py*. Add only one line to that file that looks like this, just a different key string:\n",
    "`girder_apikey_read=\"UjNzqutrfBwuk4t39VlJnJs4t3EZ6i7\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-01-14_13-05-50\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"BreastTumorSegmentationStudy\"\n",
    "\n",
    "# This should be the only parameter to update for your local environment\n",
    "\n",
    "local_data_folder = r\"c:\\Data\\BreastTumorSegmentationStudy\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 100\n",
    "batch_size = 48\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 10\n",
    "WCE_weights = np.array([0.2, 0.8])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001,\n",
    "                  0.0008, 0.0006, 0.0004, 0.0002, 0.0001]\n",
    "\n",
    "# For debugging only\n",
    "\n",
    "#limit_validation_rounds = -1\n",
    "# limit_validation_rounds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import sample\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import sagittal_spine_segmentation_unet as unet\n",
    "import evaluation_metrics\n",
    "\n",
    "\n",
    "from girder_apikey_read import girder_apikey_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5e1bae9ed9e6a3be02d013bc\", #003\n",
    "    \"5dfbc687d9e6a3be02d01343\", #004-v02\n",
    "    \"5e1cb476d9e6a3be02d01425\", #005-v02\n",
    "    \"5e1cb685d9e6a3be02d01434\", #006-v02\n",
    "    \"5e1cb84ed9e6a3be02d0143a\", #007-v02\n",
    "    \"5e14cef4d9e6a3be02d01377\", #008-v02\n",
    "    \"5e14cef4d9e6a3be02d0137a\", #009-v02\n",
    "    \"5e1cba04d9e6a3be02d01440\", #010-v02\n",
    "    \"5e1cbd21d9e6a3be02d01446\", #011\n",
    "    \"5e1cbf54d9e6a3be02d0144c\", #012\n",
    "    \"5e1cc395d9e6a3be02d01452\", #013\n",
    "    \"5e1cc4fcd9e6a3be02d01458\", #014\n",
    "    \"5e14cef4d9e6a3be02d0137d\", #015\n",
    "    \"5e1cc907d9e6a3be02d0145e\", #016\n",
    "    \"5e1cca85d9e6a3be02d01464\", #018\n",
    "    \"5e1ccb5dd9e6a3be02d0146a\", #019\n",
    "    \"5e1cb5ced9e6a3be02d0142b\", #020\n",
    "    \"5e16028cd9e6a3be02d01386\", #021\n",
    "    \"5e163f18d9e6a3be02d01392\", #022\n",
    "    \"5e163f0dd9e6a3be02d0138c\", #023\n",
    "    \"5e163f22d9e6a3be02d01398\", #024\n",
    "    \"5e163f2ad9e6a3be02d0139e\", #025\n",
    "    \"5e1c99f1d9e6a3be02d01401\", #026\n",
    "    \"5e1c99f1d9e6a3be02d01404\", #027\n",
    "    \"5e1c99f2d9e6a3be02d01407\", #028\n",
    "    \"5e1c99f2d9e6a3be02d0140a\", #029\n",
    "    \"5e1c99f3d9e6a3be02d0140d\", #030\n",
    "    \"5e1c99f3d9e6a3be02d01410\" #031\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"ultrasound-003-v02.npy\",\n",
    "    \"ultrasound-004-v02.npy\",\n",
    "    \"ultrasound-005-v02.npy\",\n",
    "    \"ultrasound-006-v02.npy\",\n",
    "    \"ultrasound-007-v02.npy\",\n",
    "    \"ultrasound-008-v02.npy\",\n",
    "    \"ultrasound-009-v02.npy\",\n",
    "    \"ultrasound-010-v02.npy\",\n",
    "    \"ultrasound-011.npy\",\n",
    "    \"ultrasound-012.npy\",\n",
    "    \"ultrasound-013.npy\",\n",
    "    \"ultrasound-014.npy\",\n",
    "    \"ultrasound-015.npy\",\n",
    "    \"ultrasound-016.npy\",\n",
    "    \"ultrasound-018.npy\",\n",
    "    \"ultrasound-019.npy\",\n",
    "    \"ultrasound-020.npy\",\n",
    "    \"ultrasound-021.npy\",\n",
    "    \"ultrasound-022.npy\",\n",
    "    \"ultrasound-023.npy\",\n",
    "    \"ultrasound-024.npy\",\n",
    "    \"ultrasound-025.npy\",\n",
    "    \"ultrasound-026.npy\",\n",
    "    \"ultrasound-027.npy\",\n",
    "    \"ultrasound-028.npy\",\n",
    "    \"ultrasound-029.npy\",\n",
    "    \"ultrasound-030.npy\",\n",
    "    \"ultrasound-031.npy\",\n",
    "]\n",
    "\n",
    "testing_ultrasound__ids = [\n",
    "    \"5e1c99f4d9e6a3be02d01413\", #032\n",
    "    \"5e1c99f5d9e6a3be02d01416\", #035\n",
    "    \"5e1c99f5d9e6a3be02d01419\", #037\n",
    "    \"5e1c99f6d9e6a3be02d0141c\", #038\n",
    "    \"5e1c99f6d9e6a3be02d0141f\", #039\n",
    "]\n",
    "\n",
    "testing_ultrasound_filenames = [\n",
    "    \"ultrasound-032.npy\",\n",
    "    \"ultrasound-035.npy\",\n",
    "    \"ultrasound-037.npy\",\n",
    "    \"ultrasound-038.npy\",\n",
    "    \"ultrasound-039.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5e1bae9ed9e6a3be02d013b9\", #003\n",
    "    \"5dfbc686d9e6a3be02d01340\", #004-v02\n",
    "    \"5e1cb475d9e6a3be02d01422\", #005-v02\n",
    "    \"5e1cb684d9e6a3be02d01431\", #006-v02\n",
    "    \"5e1cb84dd9e6a3be02d01437\", #007-v02\n",
    "    \"5e14cef3d9e6a3be02d0136e\", #008-v02\n",
    "    \"5e14cef3d9e6a3be02d01371\", #009-v02\n",
    "    \"5e1cba04d9e6a3be02d0143d\", #010-v02\n",
    "    \"5e1cbd20d9e6a3be02d01443\", #011\n",
    "    \"5e1cbf54d9e6a3be02d01449\", #012\n",
    "    \"5e1cc395d9e6a3be02d0144f\", #013\n",
    "    \"5e1cc4fcd9e6a3be02d01455\", #014\n",
    "    \"5e14cef3d9e6a3be02d01374\", #015\n",
    "    \"5e1cc906d9e6a3be02d0145b\", #016\n",
    "    \"5e1cca84d9e6a3be02d01461\", #018\n",
    "    \"5e1ccb5cd9e6a3be02d01467\", #019\n",
    "    \"5e1cb5ced9e6a3be02d01428\", #020\n",
    "    \"5e16028bd9e6a3be02d01383\", #021\n",
    "    \"5e163f17d9e6a3be02d0138f\", #022\n",
    "    \"5e163f0cd9e6a3be02d01389\", #023\n",
    "    \"5e163f21d9e6a3be02d01395\", #024\n",
    "    \"5e163f29d9e6a3be02d0139b\", #025\n",
    "    \"5e1c99edd9e6a3be02d013e0\", #026\n",
    "    \"5e1c99edd9e6a3be02d013e3\", #027\n",
    "    \"5e1c99edd9e6a3be02d013e6\", #028\n",
    "    \"5e1c99eed9e6a3be02d013e9\", #029\n",
    "    \"5e1c99eed9e6a3be02d013ec\", #030\n",
    "    \"5e1c99eed9e6a3be02d013ef\" #031\n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"segmentation-003-v02.npy\",\n",
    "    \"segmentation-004-v02.npy\",\n",
    "    \"segmentation-005-v02.npy\",\n",
    "    \"segmentation-006-v02.npy\",\n",
    "    \"segmentation-007-v02.npy\",\n",
    "    \"segmentation-008-v02.npy\",\n",
    "    \"segmentation-009-v02.npy\",\n",
    "    \"segmentation-010-v02.npy\",\n",
    "    \"segmentation-011.npy\",\n",
    "    \"segmentation-012.npy\",\n",
    "    \"segmentation-013.npy\",\n",
    "    \"segmentation-014.npy\",\n",
    "    \"segmentation-015.npy\",\n",
    "    \"segmentation-016.npy\",\n",
    "    \"segmentation-018.npy\",\n",
    "    \"segmentation-019.npy\",\n",
    "    \"segmentation-020.npy\",\n",
    "    \"segmentation-021.npy\",\n",
    "    \"segmentation-022.npy\",\n",
    "    \"segmentation-023.npy\",\n",
    "    \"segmentation-024.npy\",\n",
    "    \"segmentation-025.npy\",\n",
    "    \"segmentation-026.npy\",\n",
    "    \"segmentation-027.npy\",\n",
    "    \"segmentation-028.npy\",\n",
    "    \"segmentation-029.npy\",\n",
    "    \"segmentation-030.npy\",\n",
    "    \"segmentation-031.npy\"   \n",
    "]\n",
    "\n",
    "testing_segmentation_ids = [\n",
    "    \"5e1c99efd9e6a3be02d013f2\", #032\n",
    "    \"5e1c99efd9e6a3be02d013f5\", #035\n",
    "    \"5e1c99efd9e6a3be02d013f8\", #037\n",
    "    \"5e1c99efd9e6a3be02d013fb\", #038\n",
    "    \"5e1c99f0d9e6a3be02d013fe\" #039 \n",
    "]\n",
    "\n",
    "testing_segmentation_filenames = [\n",
    "    \"segmentation-032.npy\",\n",
    "    \"segmentation-035.npy\",\n",
    "    \"segmentation-037.npy\",\n",
    "    \"segmentation-038.npy\",\n",
    "    \"segmentation-039.npy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "results_save_folder   = \"SavedResults\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "val_data_folder       = \"PredictionsValidation\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "results_save_fullpath = os.path.join(local_data_folder, results_save_folder)\n",
    "models_save_fullpath = os.path.join(local_data_folder, models_save_folder)\n",
    "val_data_fullpath = os.path.join(local_data_folder, val_data_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(results_save_fullpath):\n",
    "    os.makedirs(results_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(results_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_fullpath):\n",
    "    os.makedirs(models_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(models_save_fullpath))\n",
    "\n",
    "if not os.path.exists(val_data_fullpath):\n",
    "    os.makedirs(val_data_fullpath)\n",
    "    print(\"Created folder: {}\".format(val_data_fullpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae4e53a4e29495fb7c9c1c2c71d3c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total download time: 0:00:00.101007\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "# Setting up number of validation rounds\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "num_validation_rounds = 7 # rounds of leave four out validation\n",
    "\n",
    "'''if limit_validation_rounds > 0:\n",
    "    num_validation_rounds = min(n_files, limit_validation_rounds)\n",
    "else:\n",
    "    num_validation_rounds = n_files'''\n",
    "\n",
    "# Preparing progress bar\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "# Downloading files\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "gclient.authenticate(apiKey=girder_apikey_read)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fe056856cf499e982a95e6a40f6481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time to load from files: 0:00:00.267014\n"
     ]
    }
   ],
   "source": [
    "# Read data into numpy arrays\n",
    "\n",
    "ultrasound_arrays = []\n",
    "segmentation_arrays = []\n",
    "\n",
    "f = IntProgress(min=0, max=n_files * 2)\n",
    "display(f)\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "\n",
    "    ultrasound_data = np.load(ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_data = np.load(segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "    \n",
    "    ultrasound_arrays.append(ultrasound_data)\n",
    "    segmentation_arrays.append(segmentation_data)\n",
    "\n",
    "time_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal time to load from files: {}\".format(time_stop - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2020-01-14_13-05-50\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    100\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     0.0001999\n",
      "Batch size:          48\n",
      "Regularization rate: 0.0001\n",
      "\n",
      "Saving validation predictions in: c:\\Data\\BreastTumorSegmentationStudy\\PredictionsValidation\n",
      "Saving models in:                 c:\\Data\\BreastTumorSegmentationStudy\\SavedModels\n",
      "\n",
      "*** Leave-four-out round # 0\n",
      "\n",
      "Training on 5031 images, validating on 1515 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victoria\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8e231f3e17cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_ultrasound_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_segmentation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Scoliosis\\Env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    \n",
    "    val_ultrasound_data = np.concatenate((ultrasound_arrays[i], ultrasound_arrays[i+1], ultrasound_arrays[i+2], ultrasound_arrays[i+3]))\n",
    "    val_segmentation_data = np.concatenate((segmentation_arrays[i], segmentation_arrays[i+1], segmentation_arrays[i+2], segmentation_arrays[i+3]))\n",
    "    val_ultrasound_filename = training_ultrasound_filenames[i] + \" \" + training_ultrasound_filenames[i+1] + \" \" + training_ultrasound_filenames[i+2] + \" \" + training_ultrasound_filenames[i+3]\n",
    "    \n",
    "    for train_index in range(n_files):\n",
    "        if train_index != i and train_index != (i+1) and train_index != (i+2) and train_index != (i+3):\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data, ultrasound_arrays[train_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data, segmentation_arrays[train_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.shape[0]\n",
    "    n_val = val_ultrasound_data.shape[0]\n",
    "    \n",
    "    print(\"\\n*** Leave-four-out round # {}\".format(i))\n",
    "    print(\"\\nTraining on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.sagittal_spine_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=[unet.weighted_categorical_crossentropy(WCE_weights)],\n",
    "        metrics=[\"accuracy\", unet.dice_coef]\n",
    "        # metrics=[\"accuracy\"]\n",
    "    )\n",
    "        \n",
    "    #model.summary()\n",
    "        \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    training_log = model.fit_generator(\n",
    "        training_generator,\n",
    "        validation_data=(val_ultrasound_data, val_segmentation_data),\n",
    "        epochs=num_epochs,\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"\\nMetrics at the end of training\")\n",
    "    print(\"  val_acc:       {}\".format(training_log.history['val_acc'][-1]))\n",
    "    print(\"  val loss:      {}\".format(training_log.history['val_loss'][-1]))\n",
    "    # print(\"  val_dice:      {}\".format(training_log.history['val_dice_coef'][-1]))\n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['acc'], 'bo--')\n",
    "    axes[1].plot(training_log.history['val_acc'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    y_pred_val  = model.predict(val_ultrasound_data)\n",
    "    \n",
    "    # Saving predictions for further evaluation\n",
    "    \n",
    "    filename_noext, extension = os.path.splitext(val_ultrasound_filename)\n",
    "    val_prediction_filename = save_timestamp + \"_prediction_\" + filename_noext + \".npy\"\n",
    "    val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "    np.save(val_prediction_fullname, y_pred_val)\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(i) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "    \n",
    "    # Validation results\n",
    "    \n",
    "    vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "        roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "    val_fuzzy_metrics[i] = evaluation_metrics.compute_evaluation_metrics(\n",
    "        y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "    val_best_metrics[i]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "    val_aurocs[i]          = vali_area\n",
    "    val_best_thresholds[i] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    results_df.loc[i] = [\n",
    "        val_aurocs[i],\n",
    "        val_best_thresholds[i],\n",
    "        val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "        val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "        val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "        val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "    ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "num_vali = val_ultrasound_data.shape[0]\n",
    "num_show = 5\n",
    "\n",
    "indices = [i for i in range(num_vali)]\n",
    "sample_indices = sample(indices, num_show)\n",
    "\n",
    "# Uncomment for comparing the same images\n",
    "sample_indices = [105, 195, 391, 133, 142]\n",
    "\n",
    "fig = plt.figure(figsize=(18, num_show*5))\n",
    "for i in range(num_show):\n",
    "    a0 = fig.add_subplot(num_show,3,i*3+1)\n",
    "    img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[i], :, :, 0].astype(np.float32)))\n",
    "    a0.set_title(\"Ultrasound #{}\".format(sample_indices[i]))\n",
    "    a1 = fig.add_subplot(num_show,3,i*3+2)\n",
    "    img1 = a1.imshow(np.flipud(val_segmentation_data[sample_indices[i], :, :, 0]), vmin=0.0, vmax=1.0)\n",
    "    a1.set_title(\"Segmentation #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "    a2 = fig.add_subplot(num_show,3,i*3+3)\n",
    "    img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a2.set_title(\"Prediction #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img2, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
