{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = \"d:\\Data\\SagittalSpineSegmentationStudy\"\n",
    "\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "batch_size = 24\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "WCE_weights = np.array([0.05, 0.95])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os \n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import sagittal_spine_segmentation_unet as unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5da9e5c0d9e6a3be02d012b4\",\n",
    "    \"5da9e5c7d9e6a3be02d012c6\",\n",
    "    \"5da9e5c2d9e6a3be02d012b7\",\n",
    "    \"5da9e5c3d9e6a3be02d012ba\",\n",
    "    \"5da9e5c8d9e6a3be02d012c9\",\n",
    "    \"5da9e5c5d9e6a3be02d012c0\",\n",
    "    \"5da9e5c6d9e6a3be02d012c3\",\n",
    "    \"5da9e5c4d9e6a3be02d012bd\"\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"q000_ultrasound.npy\",\n",
    "    \"q001_ultrasound.npy\",\n",
    "    \"q002_ultrasound.npy\",\n",
    "    \"q003_ultrasound.npy\",\n",
    "    \"q004_ultrasound.npy\",\n",
    "    \"q005_ultrasound.npy\",\n",
    "    \"q006_ultrasound.npy\",\n",
    "    \"q007_ultrasound.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5da9e5c8d9e6a3be02d012cc\",\n",
    "    \"5da9e5ccd9e6a3be02d012de\",\n",
    "    \"5da9e5c9d9e6a3be02d012cf\",\n",
    "    \"5da9e5cad9e6a3be02d012d2\",\n",
    "    \"5da9e5cdd9e6a3be02d012e1\",\n",
    "    \"5da9e5cbd9e6a3be02d012d8\",\n",
    "    \"5da9e5cbd9e6a3be02d012db\",\n",
    "    \"5da9e5cad9e6a3be02d012d5\"\n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"q000_segmentation.npy\",\n",
    "    \"q001_segmentation.npy\",\n",
    "    \"q002_segmentation.npy\",\n",
    "    \"q003_segmentation.npy\",\n",
    "    \"q004_segmentation.npy\",\n",
    "    \"q005_segmentation.npy\",\n",
    "    \"q006_segmentation.npy\",\n",
    "    \"q007_segmentation.npy\"\n",
    "]\n",
    "\n",
    "testing_ultrasound_filename = \"ultrasound-test.npy\"\n",
    "testing_ultrasound_id = \"5daa85edd9e6a3be02d012e7\"\n",
    "testing_segmentation_filename = \"segmentation-test.npy\"\n",
    "testing_segmentation_id = \"5daa85e7d9e6a3be02d012e4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "models_save_folder = os.path.join(local_data_folder, models_save_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_folder):\n",
    "    os.makedirs(models_save_folder)\n",
    "    print(\"Created folder: {}\".format(models_save_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf85eaa7afd4335b334a2573ef5abab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total download time: 0:00:00.014961\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "test_ultrasound_fullname = os.path.join(data_arrays_fullpath, testing_ultrasound_filename)\n",
    "if not os.path.exists(test_ultrasound_fullname):\n",
    "    print(\"Downloading {}...\".format(test_ultrasound_fullname))\n",
    "    gclient.downloadFile(testing_ultrasound_id, test_ultrasound_fullname)\n",
    "\n",
    "test_segmentation_fullname = os.path.join(data_arrays_fullpath, testing_segmentation_filename)\n",
    "if not os.path.exists(test_segmentation_fullname) or overwrite_existing_data_files:\n",
    "    print(\"Downloading {}...\".format(test_segmentation_fullname))\n",
    "    gclient.downloadFile(testing_segmentation_id, test_segmentation_fullname)\n",
    "    \n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ee6f6fa2a6416388d4d7a853cf48f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time to load from files: 0:00:00.118717\n"
     ]
    }
   ],
   "source": [
    "# Read data into numpy arrays\n",
    "\n",
    "ultrasound_arrays = []\n",
    "segmentation_arrays = []\n",
    "\n",
    "f = IntProgress(min=0, max=n_files * 2)\n",
    "display(f)\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "\n",
    "    ultrasound_data = np.load(ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_data = np.load(segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "    \n",
    "    ultrasound_arrays.append(ultrasound_data)\n",
    "    segmentation_arrays.append(segmentation_data)\n",
    "\n",
    "test_ultrasound_fullname = os.path.join(data_arrays_fullpath, testing_ultrasound_filename)\n",
    "test_ultrasound_array = np.load(test_ultrasound_fullname)\n",
    "\n",
    "test_segmentation_fullname = os.path.join(data_arrays_fullpath, testing_segmentation_filename)\n",
    "test_segmentation_array = np.load(test_segmentation_fullname)\n",
    "    \n",
    "time_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal time to load from files: {}\".format(time_stop - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "ultr 0 : (523, 128, 128, 1)\n",
      "segm 0 : (523, 128, 128, 1)\n",
      "ultr 1 : (355, 128, 128, 1)\n",
      "segm 1 : (355, 128, 128, 1)\n",
      "ultr 2 : (477, 128, 128, 1)\n",
      "segm 2 : (477, 128, 128, 1)\n",
      "ultr 3 : (453, 128, 128, 1)\n",
      "segm 3 : (453, 128, 128, 1)\n",
      "ultr 4 : (289, 128, 128, 1)\n",
      "segm 4 : (289, 128, 128, 1)\n",
      "ultr 5 : (387, 128, 128, 1)\n",
      "segm 5 : (387, 128, 128, 1)\n",
      "ultr 6 : (360, 128, 128, 1)\n",
      "segm 6 : (360, 128, 128, 1)\n",
      "ultr 7 : (446, 128, 128, 1)\n",
      "segm 7 : (446, 128, 128, 1)\n",
      "\n",
      "Testing data\n",
      "test ultr : (1892, 128, 128, 1)\n",
      "test segm : (1892, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print data sizes\n",
    "\n",
    "print(\"Training data\")\n",
    "for i in range(n_files):\n",
    "    print(\"ultr {} : {}\".format(i, ultrasound_arrays[i].shape))\n",
    "    print(\"segm {} : {}\".format(i, segmentation_arrays[i].shape))\n",
    "\n",
    "print(\"\\nTesting data\")\n",
    "print(\"test ultr : {}\".format(test_ultrasound_array.shape))\n",
    "print(\"test segm : {}\".format(test_segmentation_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at: 2019-10-19 13:09:28.124759\n",
      "Number of epochs:    5\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     0.003998\n",
      "Batch size:          24\n",
      "Regularization rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1019 13:09:29.125057 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1019 13:09:29.145004 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1019 13:09:29.148993 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1019 13:09:29.275654 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation ultrasound shape:   (2767, 128, 128, 1)\n",
      "Validation segmentation shape: (2767, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 13:09:29.440242 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1019 13:09:29.446200 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1019 13:09:29.615772 18976 deprecation.py:323] From e:\\dlenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1019 13:09:30.014706 18976 deprecation_wrapper.py:119] From e:\\dlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\dlenv\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:611: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 12s 102ms/step - loss: 0.0115 - acc: 0.9748 - dice_coef: 0.9842 - val_loss: 0.0066 - val_acc: 0.9890 - val_dice_coef: 0.9910\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 8s 72ms/step - loss: 0.0083 - acc: 0.9846 - dice_coef: 0.9888 - val_loss: 0.0064 - val_acc: 0.9899 - val_dice_coef: 0.9921\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 8s 72ms/step - loss: 0.0083 - acc: 0.9838 - dice_coef: 0.9886 - val_loss: 0.0064 - val_acc: 0.9890 - val_dice_coef: 0.9916\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 8s 72ms/step - loss: 0.0082 - acc: 0.9838 - dice_coef: 0.9886 - val_loss: 0.0063 - val_acc: 0.9892 - val_dice_coef: 0.9919\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 8s 71ms/step - loss: 0.0083 - acc: 0.9838 - dice_coef: 0.9887 - val_loss: 0.0063 - val_acc: 0.9893 - val_dice_coef: 0.9920\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9892585334323701\n",
      "  val loss:  0.006322275736324844\n",
      "  val_dice:  0.992009196962629\n",
      "  Total training time: 0:00:45.902717\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2935, 128, 128, 1)\n",
      "Validation segmentation shape: (2935, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "122/122 [==============================] - 9s 75ms/step - loss: 0.0090 - acc: 0.9860 - dice_coef: 0.9886 - val_loss: 0.0075 - val_acc: 0.9853 - val_dice_coef: 0.9858\n",
      "Epoch 2/5\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 0.0072 - acc: 0.9871 - dice_coef: 0.9900 - val_loss: 0.0078 - val_acc: 0.9721 - val_dice_coef: 0.9762\n",
      "Epoch 3/5\n",
      "122/122 [==============================] - 9s 72ms/step - loss: 0.0055 - acc: 0.9858 - dice_coef: 0.9902 - val_loss: 0.0065 - val_acc: 0.9660 - val_dice_coef: 0.9790\n",
      "Epoch 4/5\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 0.0051 - acc: 0.9838 - dice_coef: 0.9900 - val_loss: 0.0080 - val_acc: 0.9454 - val_dice_coef: 0.9682\n",
      "Epoch 5/5\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 0.0051 - acc: 0.9833 - dice_coef: 0.9899 - val_loss: 0.0071 - val_acc: 0.9548 - val_dice_coef: 0.9732\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9548025556973049\n",
      "  val loss:  0.00711221929772624\n",
      "  val_dice:  0.9731827420847756\n",
      "  Total training time: 0:00:45.172149\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2813, 128, 128, 1)\n",
      "Validation segmentation shape: (2813, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0084 - acc: 0.9840 - dice_coef: 0.9886 - val_loss: 0.0068 - val_acc: 0.9848 - val_dice_coef: 0.9902\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 8s 72ms/step - loss: 0.0070 - acc: 0.9830 - dice_coef: 0.9883 - val_loss: 0.0061 - val_acc: 0.9888 - val_dice_coef: 0.9900\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 8s 72ms/step - loss: 0.0068 - acc: 0.9852 - dice_coef: 0.9884 - val_loss: 0.0061 - val_acc: 0.9921 - val_dice_coef: 0.9925\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 8s 72ms/step - loss: 0.0068 - acc: 0.9857 - dice_coef: 0.9885 - val_loss: 0.0060 - val_acc: 0.9912 - val_dice_coef: 0.9900\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 8s 72ms/step - loss: 0.0068 - acc: 0.9859 - dice_coef: 0.9886 - val_loss: 0.0059 - val_acc: 0.9902 - val_dice_coef: 0.9900\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9902458849706148\n",
      "  val loss:  0.005920255581211103\n",
      "  val_dice:  0.990003880701567\n",
      "  Total training time: 0:00:44.220742\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2837, 128, 128, 1)\n",
      "Validation segmentation shape: (2837, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "118/118 [==============================] - 10s 81ms/step - loss: 0.0097 - acc: 0.9829 - dice_coef: 0.9877 - val_loss: 0.0098 - val_acc: 0.9803 - val_dice_coef: 0.9875\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 9s 74ms/step - loss: 0.0078 - acc: 0.9855 - dice_coef: 0.9896 - val_loss: 0.0099 - val_acc: 0.9824 - val_dice_coef: 0.9889\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 9s 75ms/step - loss: 0.0077 - acc: 0.9849 - dice_coef: 0.9895 - val_loss: 0.0098 - val_acc: 0.9831 - val_dice_coef: 0.9893\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.0077 - acc: 0.9846 - dice_coef: 0.9894 - val_loss: 0.0098 - val_acc: 0.9814 - val_dice_coef: 0.9884\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.0077 - acc: 0.9847 - dice_coef: 0.9895 - val_loss: 0.0097 - val_acc: 0.9801 - val_dice_coef: 0.9878\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9800793694125282\n",
      "  val loss:  0.009665267826575372\n",
      "  val_dice:  0.9877979225582547\n",
      "  Total training time: 0:00:45.359723\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (3001, 128, 128, 1)\n",
      "Validation segmentation shape: (3001, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 10s 78ms/step - loss: 0.0095 - acc: 0.9846 - dice_coef: 0.9883 - val_loss: 0.0074 - val_acc: 0.9870 - val_dice_coef: 0.9910\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.0082 - acc: 0.9838 - dice_coef: 0.9887 - val_loss: 0.0072 - val_acc: 0.9888 - val_dice_coef: 0.9919\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.0081 - acc: 0.9836 - dice_coef: 0.9887 - val_loss: 0.0073 - val_acc: 0.9838 - val_dice_coef: 0.9895\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.0080 - acc: 0.9837 - dice_coef: 0.9888 - val_loss: 0.0072 - val_acc: 0.9856 - val_dice_coef: 0.9904\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.0079 - acc: 0.9837 - dice_coef: 0.9889 - val_loss: 0.0072 - val_acc: 0.9857 - val_dice_coef: 0.9905\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9857472280661265\n",
      "  val loss:  0.00718452090707918\n",
      "  val_dice:  0.9905062466859818\n",
      "  Total training time: 0:00:46.510645\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2903, 128, 128, 1)\n",
      "Validation segmentation shape: (2903, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 10s 81ms/step - loss: 0.0090 - acc: 0.9871 - dice_coef: 0.9888 - val_loss: 0.0082 - val_acc: 0.9753 - val_dice_coef: 0.9861\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.0070 - acc: 0.9813 - dice_coef: 0.9883 - val_loss: 0.0073 - val_acc: 0.9771 - val_dice_coef: 0.9862\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0063 - acc: 0.9824 - dice_coef: 0.9890 - val_loss: 0.0054 - val_acc: 0.9883 - val_dice_coef: 0.9931\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0053 - acc: 0.9802 - dice_coef: 0.9897 - val_loss: 0.0051 - val_acc: 0.9803 - val_dice_coef: 0.9896\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0052 - acc: 0.9803 - dice_coef: 0.9898 - val_loss: 0.0052 - val_acc: 0.9887 - val_dice_coef: 0.9936\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9887183532118797\n",
      "  val loss:  0.0052413903758861125\n",
      "  val_dice:  0.9936332143843174\n",
      "  Total training time: 0:00:45.804533\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2930, 128, 128, 1)\n",
      "Validation segmentation shape: (2930, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 0.0106 - acc: 0.9784 - dice_coef: 0.9862 - val_loss: 0.0082 - val_acc: 0.9863 - val_dice_coef: 0.9899\n",
      "Epoch 2/5\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 0.0081 - acc: 0.9858 - dice_coef: 0.9896 - val_loss: 0.0080 - val_acc: 0.9832 - val_dice_coef: 0.9884\n",
      "Epoch 3/5\n",
      "122/122 [==============================] - 9s 73ms/step - loss: 0.0080 - acc: 0.9852 - dice_coef: 0.9894 - val_loss: 0.0080 - val_acc: 0.9837 - val_dice_coef: 0.9889\n",
      "Epoch 4/5\n",
      "122/122 [==============================] - 9s 75ms/step - loss: 0.0080 - acc: 0.9850 - dice_coef: 0.9894 - val_loss: 0.0079 - val_acc: 0.9828 - val_dice_coef: 0.9883\n",
      "Epoch 5/5\n",
      "122/122 [==============================] - 9s 72ms/step - loss: 0.0080 - acc: 0.9852 - dice_coef: 0.9895 - val_loss: 0.0080 - val_acc: 0.9849 - val_dice_coef: 0.9895\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9848612427711487\n",
      "  val loss:  0.00797668353964885\n",
      "  val_dice:  0.9895325183868409\n",
      "  Total training time: 0:00:46.712106\n",
      "\n",
      "\n",
      "Validation ultrasound shape:   (2844, 128, 128, 1)\n",
      "Validation segmentation shape: (2844, 128, 128, 1)\n",
      "Epoch 1/5\n",
      "118/118 [==============================] - 10s 89ms/step - loss: 0.0091 - acc: 0.9894 - dice_coef: 0.9894 - val_loss: 0.0090 - val_acc: 0.9834 - val_dice_coef: 0.9887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "118/118 [==============================] - 8s 72ms/step - loss: 0.0077 - acc: 0.9859 - dice_coef: 0.9897 - val_loss: 0.0080 - val_acc: 0.9871 - val_dice_coef: 0.9886\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.0068 - acc: 0.9909 - dice_coef: 0.9915 - val_loss: 0.0068 - val_acc: 0.9914 - val_dice_coef: 0.9925\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.0061 - acc: 0.9896 - dice_coef: 0.9915 - val_loss: 0.0064 - val_acc: 0.9864 - val_dice_coef: 0.9901\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.0057 - acc: 0.9865 - dice_coef: 0.9909 - val_loss: 0.0058 - val_acc: 0.9811 - val_dice_coef: 0.9895\n",
      "Metrics at the end of training\n",
      "  val_acc:   0.9811056653658549\n",
      "  val loss:  0.0058406673682232695\n",
      "  val_dice:  0.9894629352622561\n",
      "  Total training time: 0:00:46.144379\n",
      "\n",
      "\n",
      "All training stopped at: 2019-10-19 13:15:45.596649\n",
      "\n",
      "Total training time:        0:06:17.471890\n"
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "print(\"Training started at: {}\".format(time_sequence_start))\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "\n",
    "for i in range(n_files):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    \n",
    "    val_ultrasound_data = ultrasound_arrays[i]\n",
    "    val_segmentation_data = segmentation_arrays[i]\n",
    "    \n",
    "    for train_index in range(n_files):\n",
    "        if train_index != i:\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data, ultrasound_arrays[train_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data, segmentation_arrays[train_index]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Validation ultrasound shape:   {}\".format(train_ultrasound_data.shape))\n",
    "    print(\"Validation segmentation shape: {}\".format(train_segmentation_data.shape))\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.sagittal_spine_unet(ultrasound_size, num_classes, regularization_rate)\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "              loss=[unet.weighted_categorical_crossentropy(WCE_weights)],\n",
    "              metrics=[\"accuracy\", unet.dice_coef])\n",
    "    \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size)\n",
    "    )\n",
    "    \n",
    "    validation_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        val_ultrasound_data,\n",
    "        val_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size)\n",
    "    )\n",
    "    \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    training_log = model.fit_generator(training_generator,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       epochs=num_epochs,\n",
    "                                       verbose=1)\n",
    "        \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"Metrics at the end of training\")\n",
    "    print(\"  val_acc:  \", training_log.history['val_acc'][-1])\n",
    "    print(\"  val loss: \", training_log.history['val_loss'][-1])\n",
    "    print(\"  val_dice: \", training_log.history['val_dice_coef'][-1])\n",
    "    print(\"  Total training time: {}\\n\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nAll training stopped at: {}\".format(time_sequence_stop))\n",
    "print(\"\\nTotal training time:        {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
