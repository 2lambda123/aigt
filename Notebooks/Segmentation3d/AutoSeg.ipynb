{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################\n",
    "# CTRL F for QUESTION to see the problematic parts\n",
    "###########################################################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "import keras.backend as k\n",
    "import keras.utils\n",
    "from keras import optimizers as opt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print(k.image_dim_ordering())\n",
    "\n",
    "k.set_image_dim_ordering('tf')\n",
    "\n",
    "#tf.keras\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.1\n",
      "divided\n",
      "normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 1.        , 0.55555556])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bnormalize(arr):\n",
    "    arrMin = np.amin(arr)\n",
    "    arrMax = np.amax(arr)\n",
    "    print(arrMin)\n",
    "    print(arrMax)\n",
    "    if arrMax != 0:\n",
    "        arr = np.subtract(arr,arrMin)\n",
    "        #print(arr)\n",
    "        arrMax = np.amax(arr)\n",
    "        arr = np.divide(arr,arrMax)\n",
    "        #print(arr)\n",
    "        print(\"divided\")\n",
    "    else:\n",
    "        print(\"error, max value is zero\")\n",
    "    print(\"normalized\")\n",
    "    return arr\n",
    "bnormalize(tempArr)\n",
    "\n",
    "#normalization for arrays that are already\n",
    "def cnormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator\n",
    "\n",
    "import keras.utils\n",
    "import scipy.ndimage\n",
    "\n",
    "max_rotation_angle = 10\n",
    "\n",
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 image_dimensions=(128, 128, 128),\n",
    "                 shuffle=True,\n",
    "                 n_channels=1,\n",
    "                 n_classes=2):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.number_of_images = self.x.shape[0]\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "        #print(self.x.shape)\n",
    "        #print(self.y.shape)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.number_of_images / self.batch_size))\n",
    "        #print(\"len\")\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        #print(self.indexes)\n",
    "        #print(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        #print(\"on epoch end\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #print(\"get1\")\n",
    "        batch_indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        #print(batch_indexes)\n",
    "        x = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        #print(\"get3\")\n",
    "        y = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        #print(\"get4\")\n",
    "        for i in range(self.batch_size):\n",
    "            print(x.shape)\n",
    "            x[i,:,:,:,:] = self.x[batch_indexes[i],:,:,:,:]\n",
    "            #print(\"x\",i)\n",
    "            #print(y.shape)\n",
    "            y[i,:,:,:,:]= self.y[batch_indexes[i],:,:,:]\n",
    "            #print(\"y,i\")\n",
    "\n",
    "        angle = np.random.randint(-max_rotation_angle, max_rotation_angle)\n",
    "        x_rot = scipy.ndimage.interpolation.rotate(x, angle, (1,2), False, mode=\"constant\", cval=0, order=0)\n",
    "        y_rot = scipy.ndimage.interpolation.rotate(x, angle, (1,2), False, mode=\"constant\", cval=0, order=0)\n",
    "\n",
    "        x_rot = np.clip(x_rot, 0.0, 1.0)\n",
    "        y_rot = np.clip(y_rot, 0.0, 1.0)\n",
    "        \n",
    "        y_onehot = keras.utils.to_categorical(y_rot, self.n_classes)\n",
    "\n",
    "        return x_rot, y_onehot\n",
    "        #print(\"returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Supine.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Supine.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Supine.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Supine.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Supine.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Prone.npy\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Supine.npy\n",
      "['E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Supine.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Supine.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Supine.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Supine.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Supine.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Prone.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Supine.npy']\n",
      "['E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Supine_normalized.npy']\n",
      "['PTMW0075_Prone', 'PTMW0075_Supine', 'PTOC0078_Prone', 'PTOC0078_Supine', 'PTOD0072_Prone', 'PTOD0072_Supine', 'PTPD0028_Prone', 'PTPD0028_Supine', 'PTPP0051_Prone', 'PTPP0051_Supine', 'PTPR0077_Prone', 'PTPR0077_Supine']\n"
     ]
    }
   ],
   "source": [
    "#These paths are specific to my computer\n",
    "#change them to match where you store your nrrds and segs\n",
    "rootPath = \"E:\\\\Patient Data Summer\\\\NN\\\\\"\n",
    "nrrdPath = \"E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\\"\n",
    "segPath = \"E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\\"\n",
    "\n",
    "nrrdFilePaths = []\n",
    "nrrdFileNames = []\n",
    "normalizedFilePaths = []\n",
    "normalizedFileNames = []\n",
    "\n",
    "labelFilePaths = []\n",
    "\n",
    "#mainly unused, i could probably remove this\n",
    "def loadNpy(name):\n",
    "    b = np.load(name)\n",
    "    return b\n",
    "\n",
    "for root, dirs, files in os.walk(nrrdPath):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"normalized.npy\") or filename.endswith(\"5dim.npy\"):\n",
    "                continue\n",
    "            elif filename.endswith(\".npy\"):\n",
    "                path=os.path.join(root,filename)\n",
    "                print(path)\n",
    "                a = loadNpy(path)\n",
    "                nrrdFilePaths.append(path)\n",
    "                #very messy, but is necessary to weed out the normalized images\n",
    "                if filename.endswith(\"normalized.npy\") or filename.endswith(\"5dim.npy\"):\n",
    "                    continue\n",
    "                elif filename.endswith(\".npy\"):\n",
    "                    noExtension = filename[:-4]\n",
    "                    nrrdFileNames.append(noExtension)\n",
    "                    normalizedFileNames.append(noExtension)\n",
    "                    newExtension = noExtension + '_normalized.npy'\n",
    "                    outPutFileName = os.path.join(root,newExtension)\n",
    "                    normalizedFilePaths.append(outPutFileName)\n",
    "                \n",
    "\n",
    "print(nrrdFilePaths)\n",
    "print(normalizedFilePaths)\n",
    "print(nrrdFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTMW0075_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTMW0075_SupSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOC0078_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOC0078_SupSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOD0072_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOD0072_SupSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPD0028_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPD0028_SupSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPP0051_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPP0051_SupSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPR0077_ProSegLabel_downsized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPR0077_SupSegLabel_downsized.npy']\n"
     ]
    }
   ],
   "source": [
    "#get labels\n",
    "#I dont normalize these because they are based on binary label maps\n",
    "downsizedLabelFilePaths=[]\n",
    "labelFilePaths=[]\n",
    "for root, dirs, files in os.walk(segPath):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"Label.npy\"):                \n",
    "                noExtension = filename[:-4]\n",
    "                newExtension = noExtension + '_downsized.npy'\n",
    "                outPutFileName = os.path.join(root,newExtension)\n",
    "                downsizedLabelFilePaths.append(outPutFileName)\n",
    "                \n",
    "                path=os.path.join(root,filename)\n",
    "                labelFilePaths.append(path)\n",
    "print(downsizedLabelFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Supine.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Supine.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Supine.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Supine.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Supine.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Prone.npy\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Supine.npy\n",
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#downsize CTs\n",
    "zResize = []\n",
    "from scipy.ndimage import zoom\n",
    "nnnn=0\n",
    "for i in nrrdFilePaths:\n",
    "    print(i)\n",
    "    a = loadNpy(i)\n",
    "    a = zoom(a, (0.25,0.25,0.25))\n",
    "    b=a.shape\n",
    "    c=(b[0])\n",
    "    d=128/c\n",
    "    zResize.append(d)\n",
    "    a=zoom(a, (d,1,1))\n",
    "    print(a.shape)\n",
    "    np.save(normalizedFilePaths[nnnn],a)\n",
    "    nnnn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Segs\\PTMW0075_ProSegLabel.npy\n",
      "(652, 512, 512)\n",
      "(163, 128, 128)\n",
      "0.7852760736196319\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTMW0075_SupSegLabel.npy\n",
      "(578, 512, 512)\n",
      "(144, 128, 128)\n",
      "0.8888888888888888\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOC0078_ProSegLabel.npy\n",
      "(647, 512, 512)\n",
      "(162, 128, 128)\n",
      "0.7901234567901234\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOC0078_SupSegLabel.npy\n",
      "(631, 512, 512)\n",
      "(158, 128, 128)\n",
      "0.810126582278481\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOD0072_ProSegLabel.npy\n",
      "(613, 512, 512)\n",
      "(153, 128, 128)\n",
      "0.8366013071895425\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOD0072_SupSegLabel.npy\n",
      "(571, 512, 512)\n",
      "(143, 128, 128)\n",
      "0.8951048951048951\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPD0028_ProSegLabel.npy\n",
      "(586, 512, 512)\n",
      "(146, 128, 128)\n",
      "0.8767123287671232\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPD0028_SupSegLabel.npy\n",
      "(526, 512, 512)\n",
      "(132, 128, 128)\n",
      "0.9696969696969697\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPP0051_ProSegLabel.npy\n",
      "(799, 512, 512)\n",
      "(200, 128, 128)\n",
      "0.64\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPP0051_SupSegLabel.npy\n",
      "(573, 512, 512)\n",
      "(143, 128, 128)\n",
      "0.8951048951048951\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPR0077_ProSegLabel.npy\n",
      "(713, 512, 512)\n",
      "(178, 128, 128)\n",
      "0.7191011235955056\n",
      "(128, 128, 128)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPR0077_SupSegLabel.npy\n",
      "(621, 512, 512)\n",
      "(155, 128, 128)\n",
      "0.8258064516129032\n",
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#downsize labels\n",
    "nnnnn=0\n",
    "for i in labelFilePaths:\n",
    "    print(i)\n",
    "    a = loadNpy(i)\n",
    "    print(a.shape)\n",
    "    a = zoom(a, (0.25,0.25,0.25))\n",
    "    print(a.shape)\n",
    "    b=a.shape\n",
    "    c=(b[0])\n",
    "    d=128/c\n",
    "    print(d)\n",
    "    zResize.append(d)\n",
    "    a=zoom(a, (d,1,1))\n",
    "    print(a.shape)\n",
    "    np.save(downsizedLabelFilePaths[nnnnn],a)\n",
    "    nnnnn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Prone_normalized.npy\n",
      "-2234\n",
      "1580\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Supine_normalized.npy\n",
      "-2234\n",
      "2060\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Prone_normalized.npy\n",
      "-2309\n",
      "2466\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Supine_normalized.npy\n",
      "-2575\n",
      "2907\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Prone_normalized.npy\n",
      "-2240\n",
      "6607\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Supine_normalized.npy\n",
      "-2335\n",
      "6996\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Prone_normalized.npy\n",
      "-2298\n",
      "6654\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Supine_normalized.npy\n",
      "-2303\n",
      "1723\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Prone_normalized.npy\n",
      "-2272\n",
      "1687\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Supine_normalized.npy\n",
      "-2274\n",
      "1678\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Prone_normalized.npy\n",
      "-2274\n",
      "1565\n",
      "divided\n",
      "normalized\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Supine_normalized.npy\n",
      "-2303\n",
      "1583\n",
      "divided\n",
      "normalized\n",
      "['E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Supine_normalized.npy']\n"
     ]
    }
   ],
   "source": [
    "#create the normalized images\n",
    "n=0\n",
    "for i in normalizedFilePaths:\n",
    "    print(i)\n",
    "    a = loadNpy(i)\n",
    "    b = bnormalize(a)\n",
    "    np.save(normalizedFilePaths[n],b)\n",
    "    n+=1\n",
    "print(normalizedFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTMW0075_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTMW0075_SupSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOC0078_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOC0078_SupSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOD0072_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTOD0072_SupSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPD0028_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPD0028_SupSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPP0051_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPP0051_SupSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPR0077_ProSegLabel.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Segs\\\\PTPR0077_SupSegLabel.npy']\n"
     ]
    }
   ],
   "source": [
    "print(labelFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostly borrowed from an article online\n",
    "#i probably wont use this in the final version, this is mainly a placeholder for testing\n",
    "smooth = 1\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = k.flatten(y_true)\n",
    "    y_pred_f = k.flatten(y_pred)\n",
    "    intersection = k.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return (2 * intersection + smooth) / (k.sum(y_true_f) + k.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def IOU(true, pred):\n",
    "\n",
    "    tresholds = [0.5 + (i*.05)  for i in range(10)]\n",
    "\n",
    "    #flattened images (batch, pixels)\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = castF(K.greater(pred, 0.5))\n",
    "\n",
    "    #total white pixels - (batch,)\n",
    "    trueSum = K.sum(true, axis=-1)\n",
    "    predSum = K.sum(pred, axis=-1)\n",
    "\n",
    "    #has mask or not per image - (batch,)\n",
    "    true1 = castF(K.greater(trueSum, 1))    \n",
    "    pred1 = castF(K.greater(predSum, 1))\n",
    "\n",
    "    #to get images that have mask in both true and pred\n",
    "    truePositiveMask = castB(true1 * pred1)\n",
    "\n",
    "    #separating only the possible true positives to check iou\n",
    "    testTrue = tf.boolean_mask(true, truePositiveMask)\n",
    "    testPred = tf.boolean_mask(pred, truePositiveMask)\n",
    "\n",
    "    #getting iou and threshold comparisons\n",
    "    iou = iou_loss_core(testTrue,testPred) \n",
    "    truePositives = [castF(K.greater(iou, tres)) for tres in tresholds]\n",
    "\n",
    "    #mean of thressholds for true positives and total sum\n",
    "    truePositives = K.mean(K.stack(truePositives, axis=-1), axis=-1)\n",
    "    truePositives = K.sum(truePositives)\n",
    "\n",
    "    #to get images that don't have mask in both true and pred\n",
    "    trueNegatives = (1-true1) * (1 - pred1) # = 1 -true1 - pred1 + true1*pred1\n",
    "    trueNegatives = K.sum(trueNegatives) \n",
    "\n",
    "    return (truePositives + trueNegatives) / castF(K.shape(true)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTMW0075_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOC0078_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTOD0072_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPD0028_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPP0051_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Prone_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Nrrds\\PTPR0077_Supine_normalized.npy\n",
      "(128, 128, 128, 1)\n",
      "(12, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "image5Dim = []\n",
    "image5DimPaths = []\n",
    "for i in normalizedFilePaths:\n",
    "    print(i)\n",
    "    a=np.load(i)\n",
    "    a=a[...,np.newaxis]\n",
    "    i = i[:-4]\n",
    "    i=i + '_5dim.npy'\n",
    "    np.save(i,a)\n",
    "    print(np.shape(a))\n",
    "    image5Dim.append(a)\n",
    "    image5DimPaths.append(i)\n",
    "    \n",
    "print(np.shape(image5Dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Patient Data Summer\\NN\\Segs\\PTMW0075_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTMW0075_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOC0078_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOC0078_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOD0072_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTOD0072_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPD0028_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPD0028_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPP0051_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPP0051_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPR0077_ProSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "E:\\Patient Data Summer\\NN\\Segs\\PTPR0077_SupSegLabel_downsized.npy\n",
      "(128, 128, 128, 1)\n",
      "(12, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "label5Dim = []\n",
    "label5DimPaths = []\n",
    "\n",
    "for i in downsizedLabelFilePaths:\n",
    "    print(i)\n",
    "    a=np.load(i)\n",
    "    a=a[...,np.newaxis]\n",
    "    i = i[:-4]\n",
    "    i=i + '_5dim.npy'\n",
    "    np.save(i,a)\n",
    "    print(np.shape(a))\n",
    "    label5Dim.append(a)\n",
    "    label5DimPaths.append(i)\n",
    "    \n",
    "print(np.shape(label5Dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#might not be necessary, but creates a list of the actual arrays, not just the paths\n",
    "nn=0\n",
    "listOfNormalized=[]\n",
    "for i in normalizedFilePaths:  \n",
    "    a=np.load(i)\n",
    "    listOfNormalized.append(a)\n",
    "    nn+=1\n",
    "    print(np.shape(normalizedFilePaths))\n",
    "#print(listOfNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above but for labels\n",
    "#please excuse the variable names\n",
    "nnn=0\n",
    "listOfLabels=[]\n",
    "for i in downsizedLabelFilePaths:  \n",
    "    a=np.load(i)\n",
    "    listOfLabels.append(a)\n",
    "    nnn+=1\n",
    "#print(listOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 128, 128, 128, 1)\n",
      "(11, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (image5Dim, label5Dim, test_size = 0.05, random_state = 0)\n",
    "\n",
    "\n",
    "#print(X_train)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData=BatchGenerator(np.array(X_train),np.array(y_train),1)\n",
    "validationData=BatchGenerator(np.array(X_test),np.array(y_test),1)\n",
    "#print(np.shape(trainingData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train=[]\n",
    "new_y_train=[]\n",
    "new_Xy_train=[]\n",
    "for i in X_train:\n",
    "    for ii in y_train:\n",
    "        generated=BatchGenerator(np.array(i),np.array(ii),2)\n",
    "        new_Xy_train.append(generated)\n",
    "#rint(np.shape(np.array(new_Xy_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(rrrrrrrrrrrrrrr[0,0,50,0])\n",
    "#plt.imshow(tttttttttttttt[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n",
      "(1, 1, 128, 128, 128)\n",
      "(128, 128, 128)\n",
      "(1, 1, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#unused as of right now, will probably remove soon\n",
    "testInput1=np.load(normalizedFilePaths[0])\n",
    "print(np.shape(testInput1))\n",
    "testInput1=testInput1[np.newaxis,np.newaxis,...]\n",
    "print(np.shape(testInput1))\n",
    "\n",
    "testLabel1=np.load(downsizedLabelFilePaths[0])\n",
    "print(np.shape(testLabel1))\n",
    "testLabel1=testLabel1[np.newaxis,np.newaxis,...]\n",
    "\n",
    "#print(testInput1)\n",
    "\n",
    "print(np.shape(testLabel1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 128, 128, 128, 1)\n",
      "(11, 128, 128, 128, 1)\n",
      "['E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTMW0075_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOC0078_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTOD0072_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPD0028_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPP0051_Supine_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Prone_normalized.npy', 'E:\\\\Patient Data Summer\\\\NN\\\\Nrrds\\\\PTPR0077_Supine_normalized.npy']\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array(X_train)))\n",
    "print(np.shape(y_train))\n",
    "print(normalizedFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "aug = ImageDataGenerator(rotation_range=20, \n",
    "                         zoom_range=0.15, \n",
    "                         width_shift_range=0.2, \n",
    "                         height_shift_range=0.2, \n",
    "                         shear_range=0.15,\n",
    "                         horizontal_flip=True, \n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 8, 8, 128)\n",
      "(?, 16, 16, 16, 128)\n",
      "(?, 16, 16, 16, 256)\n",
      "(?, 16, 16, 16, 32)\n",
      "(?, 16, 16, 16, 32)\n",
      "(?, 32, 32, 32, 16)\n",
      "(?, 64, 64, 64, 16)\n",
      "(?, 128, 128, 128, 8)\n",
      "(?, 128, 128, 128, 2)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 128 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_58 (Conv3D)              (None, 128, 128, 128 448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_59 (Conv3D)              (None, 128, 128, 128 6928        conv3d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling3D) (None, 64, 64, 64, 1 0           conv3d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_60 (Conv3D)              (None, 64, 64, 64, 3 13856       max_pooling3d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_61 (Conv3D)              (None, 64, 64, 64, 3 27680       conv3d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling3D) (None, 32, 32, 32, 3 0           conv3d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_62 (Conv3D)              (None, 32, 32, 32, 6 55360       max_pooling3d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_63 (Conv3D)              (None, 32, 32, 32, 6 110656      conv3d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling3D) (None, 16, 16, 16, 6 0           conv3d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_64 (Conv3D)              (None, 16, 16, 16, 1 221312      max_pooling3d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_65 (Conv3D)              (None, 16, 16, 16, 1 442496      conv3d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling3D) (None, 8, 8, 8, 128) 0           conv3d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_66 (Conv3D)              (None, 8, 8, 8, 128) 442496      max_pooling3d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_67 (Conv3D)              (None, 8, 8, 8, 128) 442496      conv3d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_13 (UpSampling3D) (None, 16, 16, 16, 1 0           conv3d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 16, 2 0           up_sampling3d_13[0][0]           \n",
      "                                                                 conv3d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_68 (Conv3D)              (None, 16, 16, 16, 3 221216      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_69 (Conv3D)              (None, 16, 16, 16, 3 27680       conv3d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_14 (UpSampling3D) (None, 32, 32, 32, 3 0           conv3d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 32, 9 0           up_sampling3d_14[0][0]           \n",
      "                                                                 conv3d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_70 (Conv3D)              (None, 32, 32, 32, 1 41488       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_71 (Conv3D)              (None, 32, 32, 32, 1 6928        conv3d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_15 (UpSampling3D) (None, 64, 64, 64, 1 0           conv3d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 64, 4 0           up_sampling3d_15[0][0]           \n",
      "                                                                 conv3d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_72 (Conv3D)              (None, 64, 64, 64, 1 20752       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_73 (Conv3D)              (None, 64, 64, 64, 1 6928        conv3d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_16 (UpSampling3D) (None, 128, 128, 128 0           conv3d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 128, 128, 128 0           up_sampling3d_16[0][0]           \n",
      "                                                                 conv3d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_74 (Conv3D)              (None, 128, 128, 128 6920        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_75 (Conv3D)              (None, 128, 128, 128 1736        conv3d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_76 (Conv3D)              (None, 128, 128, 128 434         conv3d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,097,810\n",
      "Trainable params: 2,097,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN = Model()\n",
    "inp = Input((128,128,128,1))\n",
    "learning_rate_decay = (0.0001 - 0.00001) / 25\n",
    "\n",
    "#contracting path\n",
    "conv1 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(inp)\n",
    "conv1 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv5)\n",
    "print(conv5.shape)\n",
    "\n",
    "#expansion path\n",
    "up6 = UpSampling3D((2, 2, 2),data_format='channels_last')(conv5)\n",
    "print(up6.shape)\n",
    "up6 = concatenate([up6,conv4],axis=4)\n",
    "print(up6.shape)\n",
    "conv6 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up6)\n",
    "print(conv6.shape)\n",
    "conv6 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "print(conv6.shape)\n",
    "up7 = UpSampling3D((2, 2, 2),data_format='channels_last')(conv6)\n",
    "up7 = concatenate([up7,conv3],axis=4)\n",
    "conv7 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "print(conv7.shape)\n",
    "up8 = UpSampling3D((2, 2, 2),data_format='channels_last')(conv7)\n",
    "up8 = concatenate([up8,conv2],axis=4)\n",
    "conv8 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "print(conv8.shape)\n",
    "up9 = UpSampling3D((2, 2, 2),data_format='channels_last')(conv8)\n",
    "up9 = concatenate([up9,conv1],axis=4)\n",
    "conv9 = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "print(conv9.shape)\n",
    "\n",
    "conv10 = Conv3D(2, (3,3,3), activation='sigmoid', padding=\"same\")(conv9)\n",
    "print(conv10.shape)\n",
    "\n",
    "out = Model(inputs=[inp], outputs=[conv10])\n",
    "\n",
    "out.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(out, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128, 128)\n",
      "(1, 1, 128, 128, 128)\n",
      "(11, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#out.compile(optimizer=opt.Adam(lr = 1e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "#model does not work with adam optimizer\n",
    "out.compile(optimizer=keras.optimizers.SGD(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(testInput1.shape)\n",
    "print(testLabel1.shape)\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit1 = out.fit(np.array(X_train),np.array(y_train), batch_size=1, epochs=25, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 17s - loss: 0.6970 - acc: 0.4407(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 9s - loss: 0.6958 - acc: 0.4988 (1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 6s - loss: 0.6942 - acc: 0.6464(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 5s - loss: 0.6932 - acc: 0.6827(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 4s - loss: 0.6924 - acc: 0.7235(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 3s - loss: 0.6916 - acc: 0.7612(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 2s - loss: 0.6908 - acc: 0.7928(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.6883 - acc: 0.8539(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 6s 571ms/step - loss: 0.6875 - acc: 0.8671 - val_loss: 0.6772 - val_acc: 1.0000\n",
      "Epoch 2/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.6776 - acc: 0.9986(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.6766 - acc: 0.9989(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.6757 - acc: 0.9992(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 2s - loss: 0.6749 - acc: 0.9994(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.6740 - acc: 0.9995(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.6732 - acc: 0.9995(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.6723 - acc: 0.9996(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.6714 - acc: 0.9997(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.6698 - acc: 0.9997(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 441ms/step - loss: 0.6690 - acc: 0.9997 - val_loss: 0.6587 - val_acc: 1.0000\n",
      "Epoch 3/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.6589 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.6580 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.6572 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 2s - loss: 0.6563 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.6554 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.6546 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.6537 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.6528 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.6511 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 430ms/step - loss: 0.6502 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 1.0000\n",
      "Epoch 4/25\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.6397 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.6388 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.6379 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 2s - loss: 0.6370 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.6361 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.6351 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.6342 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.6332 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.6313 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 446ms/step - loss: 0.6304 - acc: 1.0000 - val_loss: 0.6190 - val_acc: 1.0000\n",
      "Epoch 5/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.6189 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.6178 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.6168 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.6146 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.6136 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.6125 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 9/11 [=======================>......] - ETA: 0s - loss: 0.6104 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.6093 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 0.6081 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 1.0000\n",
      "Epoch 6/25\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.5944 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.5932 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.5919 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.5906 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.5893 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.5882 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.5869 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.5855 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.5827 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 441ms/step - loss: 0.5812 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 1.0000\n",
      "Epoch 7/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.5629 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.5613 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.5596 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.5578 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.5561 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.5542 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.5523 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.5502 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.5465 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 468ms/step - loss: 0.5441 - acc: 1.0000 - val_loss: 0.5187 - val_acc: 1.0000\n",
      "Epoch 8/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.5150 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 4s - loss: 0.5108 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.5089 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.5044 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.4992 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.4943 - acc: 1.0000(1, 128, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.4914 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.4865 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.4752 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 438ms/step - loss: 0.4690 - acc: 1.0000 - val_loss: 0.4208 - val_acc: 1.0000\n",
      "Epoch 9/25\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.4194 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.3974 - acc: 1.0000\n",
      "(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.3823 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.3674 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.3557 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.3453 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.3317 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.3203 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.3021 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 442ms/step - loss: 0.2893 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 1.0000\n",
      "Epoch 10/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.1536 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.1443 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.1522 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.1378 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.1277 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.1274 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.1187 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.1113 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0998 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 441ms/step - loss: 0.0951 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 1.0000\n",
      "Epoch 11/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0767 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0600 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0528 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0479 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0498 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0470 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0452 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0432 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0400 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 442ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 12/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0420 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0309 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0276 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0260 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0276 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0259 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0246 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0240 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0228 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 13/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0247 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0181 - acc: 1.0000(1, 128, 128, 128, 1\n",
      "(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0175 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0169 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0164 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0161 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0157 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0157 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 449ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 14/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0113 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0117 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0118 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0115 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0127 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0124 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0122 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0120 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0122 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 15/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0146 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 4s - loss: 0.0119 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0111 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0109 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0102 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0100 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0098 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0096 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0099 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 447ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 16/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0076 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/11 [====>.........................] - ETA: 4s - loss: 0.0071 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0070 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0075 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0074 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0075 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0079 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0078 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0080 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0065 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 4s - loss: 0.0071 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0080 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0083 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0079 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0077 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0075 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0074 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0071 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "\b(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0084 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0077 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0078 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0074 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0070 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0068 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0066 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0065 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0062 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0050 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0053 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0052 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0057 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0054 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0054 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0054 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0053 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0047 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0050 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0047 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0052 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0055 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0054 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0053 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0051 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0050 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0039 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0050 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0046 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0045 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0042 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0042 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0041 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0040 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0040 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0041 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0041 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0044 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0043 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0041 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0040 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 442ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0035 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0034 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0036 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0037 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 448ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 4s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0038 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0036 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0036 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0036 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0036 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0035 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0035 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 451ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "(1, 128, 128, 128, 1)\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.0023 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 2/11 [====>.........................] - ETA: 3s - loss: 0.0034 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 3/11 [=======>......................] - ETA: 3s - loss: 0.0034 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 4/11 [=========>....................] - ETA: 3s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 5/11 [============>.................] - ETA: 2s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 6/11 [===============>..............] - ETA: 2s - loss: 0.0033 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 7/11 [==================>...........] - ETA: 1s - loss: 0.0032 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      " 8/11 [====================>.........] - ETA: 1s - loss: 0.0032 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 1.0000(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "fitted!\n"
     ]
    }
   ],
   "source": [
    "# QUESTION\n",
    "#accuracy tops at 100% VERY early, despite visually not being close to 100%\n",
    "#even by segmenting the entire image it would not return an accuracy close to 100%\n",
    "out.fit_generator(trainingData,validation_data=validationData, epochs=25, verbose=1)\n",
    "print(\"fitted!\")\n",
    "\n",
    "#out.fit_generator(aug.flow(np.array(X_train)[0,:,:,:,:],np.array(y_train)[0,:,:,:,:],batch_size=2), validation_data=(X_test, y_test),epochs=25, verbose=1, steps_per_epoch=10)\n",
    "#print(\"fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "#TODO make a path for this automatically\n",
    "name = \"model_\" + timestamp + \".h5\"\n",
    "modelPath = os.path.join(\"E:\\\\Patient Data Summer\\\\NN\\\\Output\\\\\", name)\n",
    "out.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 1)\n",
      "(1, 128, 128, 128, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[[0.71845937 0.45913717]\n",
      "    [0.80620986 0.36783385]\n",
      "    [0.8361478  0.33966607]\n",
      "    ...\n",
      "    [0.8415627  0.3260254 ]\n",
      "    [0.8219072  0.317363  ]\n",
      "    [0.72885054 0.30960763]]\n",
      "\n",
      "   [[0.790153   0.3302608 ]\n",
      "    [0.8831136  0.17474961]\n",
      "    [0.90875053 0.13172513]\n",
      "    ...\n",
      "    [0.91169506 0.11945984]\n",
      "    [0.890314   0.12509006]\n",
      "    [0.7803586  0.17767671]]\n",
      "\n",
      "   [[0.81813455 0.27394825]\n",
      "    [0.9073756  0.11130631]\n",
      "    [0.9300494  0.07526335]\n",
      "    ...\n",
      "    [0.93264014 0.06604579]\n",
      "    [0.9100417  0.07537311]\n",
      "    [0.7955743  0.13188341]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.81915104 0.2477012 ]\n",
      "    [0.905558   0.08941233]\n",
      "    [0.9278586  0.05741322]\n",
      "    ...\n",
      "    [0.92902017 0.05134776]\n",
      "    [0.9038367  0.0617981 ]\n",
      "    [0.7873014  0.11889786]]\n",
      "\n",
      "   [[0.7920362  0.24492481]\n",
      "    [0.8753674  0.09883574]\n",
      "    [0.89802617 0.06765339]\n",
      "    ...\n",
      "    [0.89827424 0.06267986]\n",
      "    [0.8700904  0.07531062]\n",
      "    [0.75317425 0.14011851]]\n",
      "\n",
      "   [[0.7002022  0.24362165]\n",
      "    [0.7537659  0.12721282]\n",
      "    [0.7699401  0.09825563]\n",
      "    ...\n",
      "    [0.7691083  0.09646028]\n",
      "    [0.74051094 0.11440864]\n",
      "    [0.64875126 0.19869077]]]\n",
      "\n",
      "\n",
      "  [[[0.7878481  0.39789623]\n",
      "    [0.88061714 0.2901037 ]\n",
      "    [0.9094495  0.24764946]\n",
      "    ...\n",
      "    [0.9139697  0.2349486 ]\n",
      "    [0.89443195 0.23492286]\n",
      "    [0.7965429  0.24824122]]\n",
      "\n",
      "   [[0.88957715 0.25178325]\n",
      "    [0.9554739  0.09024504]\n",
      "    [0.97059643 0.05364397]\n",
      "    ...\n",
      "    [0.9719911  0.04564497]\n",
      "    [0.9587361  0.05206493]\n",
      "    [0.86490685 0.09235606]]\n",
      "\n",
      "   [[0.9188186  0.18736443]\n",
      "    [0.97213906 0.04300475]\n",
      "    [0.982954   0.02070996]\n",
      "    ...\n",
      "    [0.9838648  0.01673427]\n",
      "    [0.9727867  0.02160218]\n",
      "    [0.88552177 0.05214176]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.92599857 0.16063699]\n",
      "    [0.9738678  0.02983031]\n",
      "    [0.9838363  0.01314482]\n",
      "    ...\n",
      "    [0.9839872  0.01097965]\n",
      "    [0.9718478  0.01513135]\n",
      "    [0.88039935 0.04254732]]\n",
      "\n",
      "   [[0.9058107  0.16258082]\n",
      "    [0.95844537 0.03427151]\n",
      "    [0.97114027 0.01673874]\n",
      "    ...\n",
      "    [0.9707564  0.01454109]\n",
      "    [0.9533173  0.01994929]\n",
      "    [0.8455545  0.05339095]]\n",
      "\n",
      "   [[0.8180567  0.1812293 ]\n",
      "    [0.8719025  0.05802226]\n",
      "    [0.89071465 0.03513569]\n",
      "    ...\n",
      "    [0.8897048  0.03327698]\n",
      "    [0.85825026 0.0427863 ]\n",
      "    [0.7298964  0.09822574]]]\n",
      "\n",
      "\n",
      "  [[[0.8040422  0.3766208 ]\n",
      "    [0.89822745 0.25968927]\n",
      "    [0.9264916  0.21342796]\n",
      "    ...\n",
      "    [0.93264663 0.19790974]\n",
      "    [0.91444814 0.20307916]\n",
      "    [0.8153812  0.22854847]]\n",
      "\n",
      "   [[0.910642   0.22229624]\n",
      "    [0.97009015 0.06841618]\n",
      "    [0.9820061  0.0362494 ]\n",
      "    ...\n",
      "    [0.98367    0.02929059]\n",
      "    [0.9738811  0.03510061]\n",
      "    [0.8921343  0.07098743]]\n",
      "\n",
      "   [[0.94185776 0.15936661]\n",
      "    [0.98413813 0.02957976]\n",
      "    [0.9913244  0.01214927]\n",
      "    ...\n",
      "    [0.9922061  0.00912267]\n",
      "    [0.9851289  0.01252711]\n",
      "    [0.9130442  0.03563243]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.949896   0.13426518]\n",
      "    [0.986088   0.01940075]\n",
      "    [0.992394   0.00718907]\n",
      "    ...\n",
      "    [0.992614   0.00563565]\n",
      "    [0.9848205  0.00831586]\n",
      "    [0.9094659  0.02794486]]\n",
      "\n",
      "   [[0.93294036 0.14202711]\n",
      "    [0.97613394 0.02406675]\n",
      "    [0.9850646  0.01007992]\n",
      "    ...\n",
      "    [0.98505706 0.00827971]\n",
      "    [0.97247183 0.01199093]\n",
      "    [0.8778575  0.03691375]]\n",
      "\n",
      "   [[0.8538059  0.16778278]\n",
      "    [0.9094447  0.04549357]\n",
      "    [0.92726994 0.02451545]\n",
      "    ...\n",
      "    [0.92664874 0.02250394]\n",
      "    [0.89518636 0.02949071]\n",
      "    [0.76012975 0.0742594 ]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[0.7983402  0.37047154]\n",
      "    [0.890803   0.25932825]\n",
      "    [0.9206176  0.21266785]\n",
      "    ...\n",
      "    [0.9274708  0.19678849]\n",
      "    [0.9090725  0.20299959]\n",
      "    [0.8078234  0.2327216 ]]\n",
      "\n",
      "   [[0.9070756  0.22198626]\n",
      "    [0.96805996 0.07196027]\n",
      "    [0.9810119  0.03764099]\n",
      "    ...\n",
      "    [0.9832405  0.03035489]\n",
      "    [0.97332275 0.03608316]\n",
      "    [0.8898972  0.07217741]]\n",
      "\n",
      "   [[0.94061905 0.16169468]\n",
      "    [0.98367834 0.03193697]\n",
      "    [0.9912925  0.01299334]\n",
      "    ...\n",
      "    [0.9924263  0.00977024]\n",
      "    [0.9853847  0.01312432]\n",
      "    [0.9130046  0.03614548]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.949427   0.1417473 ]\n",
      "    [0.98586607 0.02255243]\n",
      "    [0.9924452  0.00842488]\n",
      "    ...\n",
      "    [0.9926894  0.0066686 ]\n",
      "    [0.98485327 0.00948212]\n",
      "    [0.90959144 0.02985236]]\n",
      "\n",
      "   [[0.93265903 0.15266022]\n",
      "    [0.9763261  0.02811605]\n",
      "    [0.9855737  0.01172575]\n",
      "    ...\n",
      "    [0.9859077  0.00952765]\n",
      "    [0.9734523  0.01330304]\n",
      "    [0.8804886  0.03839925]]\n",
      "\n",
      "   [[0.85589683 0.17825177]\n",
      "    [0.91451406 0.05057886]\n",
      "    [0.9330567  0.02711546]\n",
      "    ...\n",
      "    [0.9329033  0.02447581]\n",
      "    [0.90214086 0.03151163]\n",
      "    [0.7696297  0.07472059]]]\n",
      "\n",
      "\n",
      "  [[[0.7700302  0.3690812 ]\n",
      "    [0.8542547  0.27930367]\n",
      "    [0.88432646 0.23702413]\n",
      "    ...\n",
      "    [0.8920027  0.22642177]\n",
      "    [0.8726188  0.23494437]\n",
      "    [0.7695739  0.26355147]]\n",
      "\n",
      "   [[0.88201535 0.24435115]\n",
      "    [0.94881016 0.10017601]\n",
      "    [0.966293   0.06003532]\n",
      "    ...\n",
      "    [0.96967924 0.05168042]\n",
      "    [0.9562665  0.06073052]\n",
      "    [0.8575303  0.10266164]]\n",
      "\n",
      "   [[0.9205344  0.19568694]\n",
      "    [0.97168475 0.05467024]\n",
      "    [0.98308814 0.02652413]\n",
      "    ...\n",
      "    [0.9848393  0.02155623]\n",
      "    [0.9739368  0.02783611]\n",
      "    [0.8836305  0.05947027]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.93177986 0.18177718]\n",
      "    [0.9753934  0.04358539]\n",
      "    [0.9853363  0.01969463]\n",
      "    ...\n",
      "    [0.9856514  0.01663631]\n",
      "    [0.97371817 0.02228117]\n",
      "    [0.8809124  0.05124068]]\n",
      "\n",
      "   [[0.91290104 0.19303763]\n",
      "    [0.9627508  0.05168676]\n",
      "    [0.9756994  0.02539507]\n",
      "    ...\n",
      "    [0.97567654 0.02176011]\n",
      "    [0.9588523  0.02802688]\n",
      "    [0.85261    0.06091541]]\n",
      "\n",
      "   [[0.8351698  0.2190445 ]\n",
      "    [0.8949251  0.08157665]\n",
      "    [0.9142492  0.04955503]\n",
      "    ...\n",
      "    [0.91425836 0.04474556]\n",
      "    [0.8833662  0.05451292]\n",
      "    [0.75559795 0.10258412]]]\n",
      "\n",
      "\n",
      "  [[[0.68914557 0.36015093]\n",
      "    [0.74585843 0.30556515]\n",
      "    [0.7680802  0.2771415 ]\n",
      "    ...\n",
      "    [0.7738308  0.27033356]\n",
      "    [0.7543038  0.2834839 ]\n",
      "    [0.6766889  0.33082202]]\n",
      "\n",
      "   [[0.7915635  0.298914  ]\n",
      "    [0.8590368  0.18795383]\n",
      "    [0.885069   0.14195707]\n",
      "    ...\n",
      "    [0.89115274 0.13105354]\n",
      "    [0.86685693 0.14758894]\n",
      "    [0.7537565  0.20354   ]]\n",
      "\n",
      "   [[0.83477044 0.2723578 ]\n",
      "    [0.8999703  0.14387211]\n",
      "    [0.92409325 0.09549728]\n",
      "    ...\n",
      "    [0.928475   0.08529502]\n",
      "    [0.90220743 0.10013443]\n",
      "    [0.7820977  0.15370682]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.84992826 0.27007475]\n",
      "    [0.9108416  0.13233525]\n",
      "    [0.9327351  0.08534849]\n",
      "    ...\n",
      "    [0.9334903  0.07657269]\n",
      "    [0.9041649  0.0906463 ]\n",
      "    [0.782703   0.14386079]]\n",
      "\n",
      "   [[0.832096   0.28827196]\n",
      "    [0.8919318  0.14928463]\n",
      "    [0.9135822  0.09963211]\n",
      "    ...\n",
      "    [0.91469324 0.09017503]\n",
      "    [0.88359106 0.10329241]\n",
      "    [0.76579034 0.15562785]]\n",
      "\n",
      "   [[0.7633911  0.30655265]\n",
      "    [0.81608903 0.18049261]\n",
      "    [0.83620155 0.13753608]\n",
      "    ...\n",
      "    [0.8352016  0.13118863]\n",
      "    [0.8032788  0.14399463]\n",
      "    [0.697109   0.19407526]]]]]\n",
      "[0.004168213810771704, 0.9999995231628418]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION\n",
    "#why is prediction instant, and outputs nothing?\n",
    "\n",
    "score = out.evaluate_generator(validationData)\n",
    "print(np.shape(X_test))\n",
    "outputSeg=out.predict(np.array(X_test))\n",
    "#outputSeg2=out.predict_generator(np.array(y_test))\n",
    "print(np.shape(outputSeg))\n",
    "print(type(outputSeg))\n",
    "#print(score)\n",
    "print(outputSeg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.682209e-07\n",
      "0.9999995\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(outputSeg))\n",
    "print(np.amax(outputSeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputSeg2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-1adb567e5c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mabsOutputSeg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputSeg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsOutputSeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbinaryMin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsOutputSeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputSeg2' is not defined"
     ]
    }
   ],
   "source": [
    "absOutputSeg = np.fabs(outputSeg2)\n",
    "\n",
    "print(np.amax(absOutputSeg))\n",
    "binaryMin=np.amin(absOutputSeg)\n",
    "\n",
    "normOutputSeg = bnormalize(outputSeg)\n",
    "\n",
    "#TODO\n",
    "#automatically determine the divisor for thresholding\n",
    "#this is the only non-automatic part\n",
    "binaryOutputSegTest = (outputSeg < 0.3229).astype(np.uint8)\n",
    "binaryOutputSeg = (outputSeg2 < binaryMin+0.003).astype(np.uint8)\n",
    "print(binaryOutputSeg)\n",
    "print(type(binaryOutputSeg))\n",
    "print(np.shape(binaryOutputSeg))\n",
    "print(binaryOutputSegTest)\n",
    "print(outputSeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryOutputSeg = (outputSeg > 0.0005).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "timestamp2 = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "ppath = os.path.join(\"E:\\\\Patient Data Summer\\\\NN\\\\Output\\\\\", timestamp2 + \".npy\")\n",
    "np.save(ppath,outputSeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dc25fbe10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#original CT\n",
    "lastNrrd=np.array(X_test)\n",
    "print(np.shape(lastNrrd))\n",
    "plt.imshow(lastNrrd[0,:,85,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dbfaaac88>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#human segmentation\n",
    "lastSeg=np.array(y_test)\n",
    "print(np.shape(lastSeg))\n",
    "plt.imshow(lastSeg[0,:,85,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dc4a601d0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Neural network segmentation converted to binary\n",
    "plt.imshow(np.array(binaryOutputSeg[0,:,85,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dc91b89b0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output from running NN on X_test\n",
    "# QUESTION\n",
    "# how do I address the fact that it seems to be segmenting the entire image\n",
    "# is this the fault of not enough samples? I thought the generator's aim was to fix that\n",
    "\n",
    "plt.imshow(np.array(outputSeg[0,:,85,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(binaryOutputSegTest[0,:,85,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output from running NN on y_test\n",
    "#aka output segmentation before binarization\n",
    "plt.imshow(np.array(outputSeg2[0,:,85,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "#itk.Image.GetTypes()\n",
    "floatBinaryOutputSeg = binaryOutputSeg.astype(np.float)\n",
    "absBinaryOutputSeg = np.fabs(binaryOutputSeg)\n",
    "timestamp3 = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "image = itk.GetImageFromArray(np.array(floatBinaryOutputSeg))\n",
    "itk.imwrite(image, timestamp3+'.nrrd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
