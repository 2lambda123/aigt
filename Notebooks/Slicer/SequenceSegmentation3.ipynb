{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained tensorflow model\n",
    "\n",
    "model_file_name = r\"SagittalSpine_04.h5\"\n",
    "models_folder_name = r\"SavedModels\"\n",
    "\n",
    "# Input ultrasound sequence names\n",
    "\n",
    "input_browser_name = r\"SagittalScan\"\n",
    "input_image_name = r\"Image_Image\"\n",
    "\n",
    "# Output will be saved using these names\n",
    "\n",
    "output_browser_name = r\"BoneSequenceBrowser\"\n",
    "output_sequence_name = r\"SegmentationSequence\"\n",
    "output_image_name = r\"Segmented_Image\"\n",
    "\n",
    "# Optionally save output to numpy arrays\n",
    "\n",
    "array_output = True\n",
    "array_folder_name = r\"Temp\"\n",
    "array_segmentation_name = r\"segmentation\"\n",
    "array_ultrasound_name = r\"ultrasound\"\n",
    "\n",
    "# Image processing parameters\n",
    "\n",
    "# Erases the side of prediction images. 1.0 means the whole prediction is erased.\n",
    "# Background should be the first component (i.e. y[:,:,:,0]) in the prediction output array.\n",
    "\n",
    "clip_side_ratio = 0.3\n",
    "apply_logarithmic_transformation = True\n",
    "logarithmic_transformation_decimals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.ndimage\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from local_vars import root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading model from: d:\\Data\\SavedModels\\SagittalSpine_04.h5\n",
       "Will save segmentation output to d:\\Data\\Temp\\segmentation\n",
       "Will save ultrasound output to   d:\\Data\\Temp\\ultrasound\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if keras model file exists. Abort if not found. Load model otherwise.\n",
    "\n",
    "models_path = os.path.join(root_folder, models_folder_name)\n",
    "model_fullpath = os.path.join(models_path, model_file_name)\n",
    "\n",
    "if not os.path.exists(model_fullpath):\n",
    "    raise Exception(\"Could not find model: \" + model_fullpath)\n",
    "\n",
    "print(\"Loading model from: \" + model_fullpath)\n",
    "\n",
    "if array_output:\n",
    "    array_output_fullpath = os.path.join(root_folder, array_folder_name)\n",
    "    array_segmentation_fullname = os.path.join(array_output_fullpath, array_segmentation_name)\n",
    "    array_ultrasound_fullname = os.path.join(array_output_fullpath, array_ultrasound_name)\n",
    "    if not os.path.exists(array_output_fullpath):\n",
    "        os.mkdir(array_output_fullpath)\n",
    "        print(\"Folder created: {}\".format(array_output_fullpath))\n",
    "    print(\"Will save segmentation output to {}\".format(array_segmentation_fullname))\n",
    "    print(\"Will save ultrasound output to   {}\".format(array_ultrasound_fullname))\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    \n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "\n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \"\"\"\n",
    "    weights = K.variable(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "wcce = weighted_categorical_crossentropy([0.05, 0.95])\n",
    "\n",
    "model = load_model(model_fullpath, custom_objects={'loss': wcce, 'dice_coef': dice_coef})\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input. Abort if browser or image doesn't exist.\n",
    "\n",
    "input_browser_node = slicer.util.getFirstNodeByName(input_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "input_image_node = slicer.util.getFirstNodeByName(input_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "\n",
    "if input_browser_node is None:\n",
    "    logging.error(\"Could not find input browser node: {}\".format(input_browser_node))\n",
    "    raise\n",
    "\n",
    "if input_image_node is None:\n",
    "    logging.error(\"Could not find input image node: {}\".format(input_image_name))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create output image and browser for segmentation output.\n",
    "\n",
    "output_browser_node = slicer.util.getFirstNodeByName(output_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "if output_browser_node is None:\n",
    "    output_browser_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceBrowserNode', output_browser_name)\n",
    "\n",
    "output_sequence_node = slicer.util.getFirstNodeByName(output_sequence_name, className=\"vtkMRMLSequenceNode\")\n",
    "if output_sequence_node is None:\n",
    "    output_sequence_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode', output_sequence_name)\n",
    "    output_browser_node.AddSynchronizedSequenceNode(output_sequence_node)\n",
    "\n",
    "output_image_node = slicer.util.getFirstNodeByName(output_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "if output_image_node is None:\n",
    "    volumes_logic = slicer.modules.volumes.logic()\n",
    "    output_image_node = volumes_logic.CloneVolume(slicer.mrmlScene, input_image_node, output_image_name)\n",
    "    browser_logic = slicer.modules.sequencebrowser.logic()\n",
    "    browser_logic.AddSynchronizedNode(output_sequence_node, output_image_node, output_browser_node)\n",
    "\n",
    "output_browser_node.SetRecording(output_sequence_node, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add all input sequences to the output browser for being able to conveniently replay everything\n",
    "\n",
    "proxy_collection = vtk.vtkCollection()\n",
    "input_browser_node.GetAllProxyNodes(proxy_collection)\n",
    "\n",
    "for i in range(proxy_collection.GetNumberOfItems()):\n",
    "    proxy_node = proxy_collection.GetItemAsObject(i)\n",
    "    output_sequence = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode')\n",
    "    browser_logic.AddSynchronizedNode(output_sequence, proxy_node, output_browser_node)\n",
    "    output_browser_node.SetRecording(output_sequence, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Will segment 3396 images\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate input sequence, compute segmentation for each frame, record output sequence.\n",
    "\n",
    "num_items = input_browser_node.GetNumberOfItems()\n",
    "n = num_items\n",
    "input_browser_node.SelectFirstItem()\n",
    "\n",
    "input_array = slicer.util.array(input_image_node.GetID())\n",
    "slicer_to_model_scaling = model.layers[0].input_shape[1] / input_array.shape[1]\n",
    "model_to_slicer_scaling = input_array.shape[1] / model.layers[0].input_shape[1]\n",
    "\n",
    "print(\"Will segment {} images\".format(n))\n",
    "\n",
    "if array_output:\n",
    "    array_output_ultrasound = np.zeros((n, input_array.shape[1], input_array.shape[1]))\n",
    "    array_output_segmentation = np.zeros((n, input_array.shape[1], input_array.shape[1]), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Will mask 19 columns on both sides\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_size = model.layers[-1].output_shape[1]\n",
    "num_output_components = model.layers[-1].output_shape[3]\n",
    "\n",
    "mask_model = np.ones([model_output_size, model_output_size])\n",
    "mask_model_background = np.zeros([model_output_size, model_output_size])\n",
    "\n",
    "columns_to_mask = int(model_output_size / 2 * clip_side_ratio)\n",
    "print(\"Will mask {} columns on both sides\".format(columns_to_mask))\n",
    "\n",
    "mask_model[:,:columns_to_mask] = 0\n",
    "mask_model[:,-columns_to_mask:] = 0\n",
    "mask_model_background[:,:columns_to_mask] = 1\n",
    "mask_model_background[:,-columns_to_mask:] = 1\n",
    "\n",
    "# Display mask\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('WXAgg')\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.imshow(mask_model[:,:])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing started at: 11-37-50\n",
       "Processing finished at: 11-45-00\n",
       "Saved d:\\Data\\Temp\\ultrasound\n",
       "Saved d:\\Data\\Temp\\segmentation\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_timestamp = datetime.datetime.now()\n",
    "print(\"Processing started at: {}\".format(start_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    # if i > 10:  # todo Just for debugging\n",
    "    #     break\n",
    "    input_array = slicer.util.array(input_image_node.GetID())\n",
    "    \n",
    "    if array_output:\n",
    "        array_output_ultrasound[i, :, :] = input_array[0, :, :]\n",
    "    \n",
    "    resized_input_array = scipy.ndimage.zoom(input_array[0,:,:], slicer_to_model_scaling)\n",
    "    resized_input_array = np.flip(resized_input_array, axis=0)\n",
    "    resized_input_array = resized_input_array / resized_input_array.max()  # Scaling intensity to 0-1\n",
    "    resized_input_array = np.expand_dims(resized_input_array, axis=0)\n",
    "    resized_input_array = np.expand_dims(resized_input_array, axis=3)\n",
    "    y = model.predict(resized_input_array)\n",
    "    if apply_logarithmic_transformation:\n",
    "        e = logarithmic_transformation_decimals\n",
    "        y = np.log10(np.clip(y, 10**(-e), 1.0)*(10**e))/e\n",
    "    y[0,:,:,:] = np.flip(y[0,:,:,:], axis=0)\n",
    "    \n",
    "    for component in range(1, num_output_components):\n",
    "        y[0,:,:,component] = y[0,:,:,component] * mask_model[:,:]\n",
    "    y[0,:,:,0] = np.maximum(y[0,:,:,0], mask_model_background)\n",
    "    \n",
    "    upscaled_output_array = scipy.ndimage.zoom(y[0,:,:,1], model_to_slicer_scaling)\n",
    "    upscaled_output_array = upscaled_output_array * 255\n",
    "    upscaled_output_array = np.clip(upscaled_output_array, 0, 255)\n",
    "    \n",
    "    if array_output:\n",
    "        array_output_segmentation[i, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "    \n",
    "    # output_array = slicer.util.array(output_image_node.GetID())\n",
    "    # output_array[0, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "    \n",
    "    slicer.util.updateVolumeFromArray(output_image_node, upscaled_output_array.astype(np.uint8)[np.newaxis, ...])\n",
    "    \n",
    "    output_browser_node.SaveProxyNodesState()\n",
    "    input_browser_node.SelectNextItem()\n",
    "    \n",
    "    slicer.app.processEvents()\n",
    "    # print(\"Processed frame {:02d} at {}\".format(i, datetime.datetime.now().strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "stop_timestamp = datetime.datetime.now()\n",
    "print(\"Processing finished at: {}\".format(stop_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "if array_output:\n",
    "    np.save(array_ultrasound_fullname, array_output_ultrasound)\n",
    "    np.save(array_segmentation_fullname, array_output_segmentation)\n",
    "    print(\"Saved {}\".format(array_ultrasound_fullname))\n",
    "    print(\"Saved {}\".format(array_segmentation_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processed 3396 frames in 430.81 seconds\n",
       "FPS = 7.88\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_seconds = (stop_timestamp - start_timestamp).total_seconds()\n",
    "print(\"Processed {} frames in {:.2f} seconds\".format(n, time_seconds))\n",
    "print(\"FPS = {:.2f}\".format(n / time_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Slicer 4.11",
   "language": "python",
   "name": "slicer-4.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
