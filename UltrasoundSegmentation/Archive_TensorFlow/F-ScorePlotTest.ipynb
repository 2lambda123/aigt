{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-08-08_16-34-43\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"F-ScorePlotTest\"\n",
    "\n",
    "# folder to save notebook html\n",
    "local_data_folder = r\"c:\\Data\\SagittalSpineSegmentationStudy\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 8\n",
    "class_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "# Validation schedule - applied across all tests\n",
    "validation_schedule_patient = np.array([[0]])\n",
    "num_validation_rounds = len(validation_schedule_patient)\n",
    "\n",
    "# uncomment for faster debugging\n",
    "# roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "# num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(local_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 has 387 ultrasounds and 387 segmentations\n",
      "Patient 1 has 360 ultrasounds and 360 segmentations\n",
      "Patient 2 has 453 ultrasounds and 453 segmentations\n",
      "Patient 3 has 289 ultrasounds and 289 segmentations\n",
      "Patient 4 has 477 ultrasounds and 477 segmentations\n",
      "Patient 5 has 446 ultrasounds and 446 segmentations\n",
      "Patient 6 has 355 ultrasounds and 355 segmentations\n",
      "Patient 7 has 523 ultrasounds and 523 segmentations\n",
      "Patient 8 has 425 ultrasounds and 425 segmentations\n",
      "Patient 9 has 502 ultrasounds and 502 segmentations\n",
      "Patient 10 has 134 ultrasounds and 134 segmentations\n",
      "Patient 11 has 77 ultrasounds and 77 segmentations\n",
      "Patient 12 has 187 ultrasounds and 187 segmentations\n",
      "Patient 13 has 79 ultrasounds and 79 segmentations\n",
      "Patient 14 has 178 ultrasounds and 178 segmentations\n",
      "Patient 15 has 26 ultrasounds and 26 segmentations\n",
      "Patient 16 has 349 ultrasounds and 349 segmentations\n",
      "Patient 17 has 378 ultrasounds and 378 segmentations\n",
      "Patient 18 has 526 ultrasounds and 526 segmentations\n",
      "Patient 19 has 4 ultrasounds and 4 segmentations\n",
      "Patient 20 has 332 ultrasounds and 332 segmentations\n",
      "Patient 21 has 172 ultrasounds and 172 segmentations\n",
      "Patient 22 has 326 ultrasounds and 326 segmentations\n"
     ]
    }
   ],
   "source": [
    "# loading patient data\n",
    "\n",
    "girder_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "from girder_api_key import girder_key\n",
    "\n",
    "data_csv_file = \"QueensSagittal.csv\"\n",
    "\n",
    "ultrasound_arrays_by_patients, segmentation_arrays_by_patients =\\\n",
    "    utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key=girder_key)\n",
    "\n",
    "data_csv_file = \"VerdureSagittal.csv\"\n",
    "\n",
    "ultrasound_arrays_by_patients2, segmentation_arrays_by_patients2 =\\\n",
    "    utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key=girder_key)\n",
    "\n",
    "ultrasound_arrays_by_patients += ultrasound_arrays_by_patients2\n",
    "segmentation_arrays_by_patients += segmentation_arrays_by_patients2\n",
    "\n",
    "n_patients = len(ultrasound_arrays_by_patients)\n",
    "\n",
    "for i in range(n_patients):\n",
    "    print(\"Patient {} has {} ultrasounds and {} segmentations\".format(\n",
    "        i, ultrasound_arrays_by_patients[i].shape[0], segmentation_arrays_by_patients[i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning test\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 360 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 0:08:03.341974\n",
      "\n",
      "Total round time:  0:08:11.379481\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 813 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 0:22:00.834477\n",
      "\n",
      "Total round time:  0:22:08.956756\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 1102 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 0:29:15.164831\n",
      "\n",
      "Total round time:  0:29:23.498545\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 1579 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 0:43:13.653688\n",
      "\n",
      "Total round time:  0:43:22.050264\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 2025 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 0:54:15.833745\n",
      "\n",
      "Total round time:  0:54:24.282181\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 2380 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:04:28.624402\n",
      "\n",
      "Total round time:  1:04:36.868359\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 2903 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:17:59.922887\n",
      "\n",
      "Total round time:  1:18:08.263582\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 3328 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:32:06.260186\n",
      "\n",
      "Total round time:  1:32:14.567968\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 3830 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:41:54.874692\n",
      "\n",
      "Total round time:  1:42:03.166548\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 3964 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:47:27.099270\n",
      "\n",
      "Total round time:  1:47:35.423015\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4041 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:49:24.471357\n",
      "\n",
      "Total round time:  1:49:32.906816\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4228 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:58:08.599927\n",
      "\n",
      "Total round time:  1:58:18.251119\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4307 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 1:56:19.749468\n",
      "\n",
      "Total round time:  1:56:27.876700\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4485 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:02:47.746008\n",
      "\n",
      "Total round time:  2:02:56.074735\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4511 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:04:46.374236\n",
      "\n",
      "Total round time:  2:04:54.697953\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 4860 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:10:51.754600\n",
      "\n",
      "Total round time:  2:11:00.126213\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 5238 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:23:58.910425\n",
      "\n",
      "Total round time:  2:24:07.432635\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 5764 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:41:02.910291\n",
      "\n",
      "Total round time:  2:41:11.432501\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 5768 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  Training time: 2:41:08.066862\n",
      "\n",
      "Total round time:  2:41:16.545193\n",
      "\n",
      "\n",
      "*** # of patients in this round: 1\n",
      "    Training on 6100 images, validating on 387 images...\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Beginning test\")\n",
    "\n",
    "f_score_list = []\n",
    "\n",
    "for i in range(2, len(ultrasound_arrays_by_patients) + 1):\n",
    "    \n",
    "    ultrasound_sub_array = ultrasound_arrays_by_patients[0:i]\n",
    "    segmentation_sub_array = segmentation_arrays_by_patients[0:i]\n",
    "    n_patients = len(ultrasound_sub_array)\n",
    "\n",
    "    # ROC data will be saved in these containers\n",
    "\n",
    "    val_best_metrics    = dict()\n",
    "    val_fuzzy_metrics   = dict()\n",
    "    val_aurocs          = np.zeros(num_validation_rounds)\n",
    "    val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "    # Perform validation rounds\n",
    "\n",
    "    for val_round_index in range(num_validation_rounds):\n",
    "\n",
    "        # Prepare data arrays\n",
    "\n",
    "        train_ultrasound_data = np.zeros(\n",
    "            [0,\n",
    "             ultrasound_sub_array[0].shape[1],\n",
    "             ultrasound_sub_array[0].shape[2],\n",
    "             ultrasound_sub_array[0].shape[3]])\n",
    "\n",
    "        train_segmentation_data = np.zeros(\n",
    "            [0,\n",
    "             segmentation_sub_array[0].shape[1],\n",
    "             segmentation_sub_array[0].shape[2],\n",
    "             segmentation_sub_array[0].shape[3]])\n",
    "\n",
    "        val_ultrasound_data = np.zeros(\n",
    "            [0,\n",
    "             ultrasound_sub_array[0].shape[1],\n",
    "             ultrasound_sub_array[0].shape[2],\n",
    "             ultrasound_sub_array[0].shape[3]])\n",
    "\n",
    "        val_segmentation_data = np.zeros(\n",
    "            [0,\n",
    "             segmentation_sub_array[0].shape[1],\n",
    "             segmentation_sub_array[0].shape[2],\n",
    "             segmentation_sub_array[0].shape[3]])\n",
    "\n",
    "        for patient_index in range(n_patients):\n",
    "            if patient_index not in validation_schedule_patient[val_round_index]:\n",
    "                train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                        ultrasound_sub_array[patient_index]))\n",
    "                train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                          segmentation_sub_array[patient_index]))\n",
    "            else:\n",
    "                val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                     ultrasound_sub_array[patient_index]))\n",
    "                val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                       segmentation_sub_array[patient_index]))\n",
    "\n",
    "        n_train = train_ultrasound_data.shape[0]\n",
    "        n_val = val_ultrasound_data.shape[0]\n",
    "\n",
    "        print(\"\\n*** # of patients in this round: {}\".format(val_round_index + 1))\n",
    "        print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "\n",
    "        val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "\n",
    "        # Create and train model\n",
    "\n",
    "        model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "\n",
    "        print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "            loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # model.summary()\n",
    "\n",
    "        training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "            train_ultrasound_data,\n",
    "            train_segmentation_data[:, :, :, 0],\n",
    "            batch_size,\n",
    "            (ultrasound_size, ultrasound_size),\n",
    "            max_shift_factor=max_shift_factor,\n",
    "            min_zoom_factor=min_zoom_factor,\n",
    "            max_zoom_factor=max_zoom_factor,\n",
    "            max_rotation_angle=max_rotation_angle\n",
    "        )\n",
    "\n",
    "        training_time_start = datetime.datetime.now()\n",
    "\n",
    "        if n_val > 0:\n",
    "            training_log = model.fit_generator(\n",
    "                training_generator,\n",
    "                validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "                epochs=num_epochs,\n",
    "                verbose=0)\n",
    "        else:\n",
    "            training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "\n",
    "        training_time_stop = datetime.datetime.now()\n",
    "\n",
    "        # Pring training log\n",
    "\n",
    "        print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "\n",
    "        # Plot training loss and metrics\n",
    "\n",
    "        # fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "        # axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "        # if n_val > 0:\n",
    "        #     axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "        # axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "        # if n_val > 0:\n",
    "        #    axes[0].legend(['Training loss', 'Validation loss'])\n",
    "\n",
    "        # axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "        # if n_val > 0:\n",
    "        #     axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "        # axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "        # if n_val > 0:\n",
    "        #     axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        # Archive trained model with unique filename based on notebook name and timestamp\n",
    "\n",
    "        model_file_name = this_notebook_name + \"_model-\" + str(i) + \"_\" + save_timestamp + \".h5\"\n",
    "        model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "        model.save(model_fullname)\n",
    "\n",
    "        # Predict on validation data\n",
    "\n",
    "        if n_val > 0:\n",
    "            y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "            # Saving predictions for further evaluation\n",
    "\n",
    "            # val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "            # val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "            # np.save(val_prediction_fullname, y_pred_val)\n",
    "\n",
    "            # Validation results\n",
    "\n",
    "            vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "                roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "            val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "                y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "            val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "            val_aurocs[val_round_index]          = vali_area\n",
    "            val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "            \n",
    "            f_score_list.append(val_fuzzy_metrics[0][evaluation_metrics.FSCORE])\n",
    "\n",
    "        # Printing total time of this validation round\n",
    "\n",
    "        print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-87fdda9b0d50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_score_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'darkred'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.plot(f_score_list, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
