{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_notebook_name = \"F-ScorePlotTest\"\n",
    "\n",
    "# folder to save notebook html\n",
    "local_data_folder = r\"c:\\Data\\SagittalSpineSegmentationStudy\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 8\n",
    "class_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "# Validation schedule - applied across all tests\n",
    "validation_schedule_patient = np.array([[0]])\n",
    "num_validation_rounds = len(validation_schedule_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(local_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading patient data\n",
    "\n",
    "girder_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "from girder_api_key import girder_key\n",
    "\n",
    "data_csv_file = \"QueensSagittal.csv\"\n",
    "\n",
    "ultrasound_arrays_by_patients, segmentation_arrays_by_patients =\\\n",
    "    utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key=girder_key)\n",
    "\n",
    "data_csv_file = \"VerdureSagittal.csv\"\n",
    "\n",
    "ultrasound_arrays_by_patients2, segmentation_arrays_by_patients2 =\\\n",
    "    utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key=girder_key)\n",
    "\n",
    "ultrasound_arrays_by_patients += ultrasound_arrays_by_patients2\n",
    "segmentation_arrays_by_patients += segmentation_arrays_by_patients2\n",
    "\n",
    "n_patients = len(ultrasound_arrays_by_patients)\n",
    "\n",
    "for i in range(n_patients):\n",
    "    print(\"Patient {} has {} ultrasounds and {} segmentations\".format(\n",
    "        i, ultrasound_arrays_by_patients[i].shape[0], segmentation_arrays_by_patients[i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Beginning test\")\n",
    "\n",
    "f_score_list = []\n",
    "\n",
    "for i in range(2, len(ultrasound_arrays_by_patients) + 1):\n",
    "    \n",
    "    ultrasound_sub_array = ultrasound_arrays_by_patients[0:i]\n",
    "    segmentation_sub_array = segmentation_arrays_by_patients[0:i]\n",
    "    n_patients = len(ultrasound_sub_array)\n",
    "\n",
    "    # ROC data will be saved in these containers\n",
    "\n",
    "    val_best_metrics    = dict()\n",
    "    val_fuzzy_metrics   = dict()\n",
    "    val_aurocs          = np.zeros(num_validation_rounds)\n",
    "    val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "    # Perform validation rounds\n",
    "\n",
    "    for val_round_index in range(num_validation_rounds):\n",
    "\n",
    "        # Prepare data arrays\n",
    "\n",
    "        train_ultrasound_data = np.zeros(\n",
    "            [0,\n",
    "             ultrasound_sub_array[0].shape[1],\n",
    "             ultrasound_sub_array[0].shape[2],\n",
    "             ultrasound_sub_array[0].shape[3]])\n",
    "\n",
    "        train_segmentation_data = np.zeros(\n",
    "            [0,\n",
    "             segmentation_sub_array[0].shape[1],\n",
    "             segmentation_sub_array[0].shape[2],\n",
    "             segmentation_sub_array[0].shape[3]])\n",
    "\n",
    "        val_ultrasound_data = np.zeros(\n",
    "            [0,\n",
    "             ultrasound_sub_array[0].shape[1],\n",
    "             ultrasound_sub_array[0].shape[2],\n",
    "             ultrasound_sub_array[0].shape[3]])\n",
    "\n",
    "        val_segmentation_data = np.zeros(\n",
    "            [0,\n",
    "             segmentation_sub_array[0].shape[1],\n",
    "             segmentation_sub_array[0].shape[2],\n",
    "             segmentation_sub_array[0].shape[3]])\n",
    "\n",
    "        for patient_index in range(n_patients):\n",
    "            if patient_index not in validation_schedule_patient[val_round_index]:\n",
    "                train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                        ultrasound_sub_array[patient_index]))\n",
    "                train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                          segmentation_sub_array[patient_index]))\n",
    "            else:\n",
    "                val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                     ultrasound_sub_array[patient_index]))\n",
    "                val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                       segmentation_sub_array[patient_index]))\n",
    "\n",
    "        n_train = train_ultrasound_data.shape[0]\n",
    "        n_val = val_ultrasound_data.shape[0]\n",
    "\n",
    "        print(\"\\n*** # of patients in this round: {}\".format(val_round_index + 1))\n",
    "        print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "\n",
    "        val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "\n",
    "        # Create and train model\n",
    "\n",
    "        model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "            loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # model.summary()\n",
    "\n",
    "        training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "            train_ultrasound_data,\n",
    "            train_segmentation_data[:, :, :, 0],\n",
    "            batch_size,\n",
    "            (ultrasound_size, ultrasound_size),\n",
    "            max_shift_factor=max_shift_factor,\n",
    "            min_zoom_factor=min_zoom_factor,\n",
    "            max_zoom_factor=max_zoom_factor,\n",
    "            max_rotation_angle=max_rotation_angle\n",
    "        )\n",
    "\n",
    "        training_time_start = datetime.datetime.now()\n",
    "\n",
    "        if n_val > 0:\n",
    "            training_log = model.fit_generator(\n",
    "                training_generator,\n",
    "                validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "                epochs=num_epochs,\n",
    "                verbose=0)\n",
    "        else:\n",
    "            training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "\n",
    "        training_time_stop = datetime.datetime.now()\n",
    "\n",
    "        # Pring training log\n",
    "\n",
    "        print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "\n",
    "        # Plot training loss and metrics\n",
    "\n",
    "        # fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "        # axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "        # if n_val > 0:\n",
    "        #     axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "        # axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "        # if n_val > 0:\n",
    "        #    axes[0].legend(['Training loss', 'Validation loss'])\n",
    "\n",
    "        # axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "        # if n_val > 0:\n",
    "        #     axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "        # axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "        # if n_val > 0:\n",
    "        #     axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        # Archive trained model with unique filename based on notebook name and timestamp\n",
    "\n",
    "        # model_file_name = this_notebook_name + \"_model-\" + str(val_round_index) + \"_\" + save_timestamp + \".h5\"\n",
    "        # model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "        # model.save(model_fullname)\n",
    "\n",
    "        # Predict on validation data\n",
    "\n",
    "        if n_val > 0:\n",
    "            y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "            # Saving predictions for further evaluation\n",
    "\n",
    "            # val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "            # val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "            # np.save(val_prediction_fullname, y_pred_val)\n",
    "\n",
    "            # Validation results\n",
    "\n",
    "            vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "                roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "            val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "                y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "            val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "            val_aurocs[val_round_index]          = vali_area\n",
    "            val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "            \n",
    "            f_score_list.append(val_fuzzy_metrics[0][evaluation_metrics.FSCORE])\n",
    "\n",
    "        # Printing total time of this validation round\n",
    "\n",
    "        print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.plot(f_score_list, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
