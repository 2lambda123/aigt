{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-06-22_16-34-28\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"SagittalSpineSegmentationStudy-TF2\"\n",
    "\n",
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = r\"C:\\Data\\SagittalSpineSegmentationStudy\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 8\n",
    "class_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "'''\n",
    "Provide NxM numpy array to schedule cross validation\n",
    "N rounds of validation will be performed, leaving out M patients in each for validation data\n",
    "All values should be valid patient IDs, or negative. Negative values are ignored.\n",
    "\n",
    "Example 1: a leave-one-out cross validation with 3 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0],[1],[2]])\n",
    "\n",
    "Example 2: a leave-two-out cross validation on 10 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0,1],[2,3],[4,5],[6,7],[8,9]])\n",
    "\n",
    "Example 3: leave-one-out cross validation with 3 patients, then training on all available data (no validation):\n",
    "validation_schedule_patient = np.array([[0],[1],[2],[-1]])\n",
    "'''\n",
    "validation_schedule_patient = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]])\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "\n",
    "# roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "# num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating aigt clone\n",
      "Updating 4718350..bb585f9\n",
      "Fast-forward\n",
      " .../Resources/UI/SingleSliceSegmentation.ui        |   2 +-\n",
      " .../SingleSliceSegmentation.py                     |  39 +\n",
      " .../BreastSegmentationStudy-TF2.ipynb              | 937 +++++++++++++++++++++\n",
      " .../SequenceSegmentation3-TF2.ipynb                | 163 +++-\n",
      " .../Slicer_PrepareSceneForSegmentation.ipynb       |  94 ++-\n",
      " 5 files changed, 1167 insertions(+), 68 deletions(-)\n",
      " create mode 100644 UltrasoundSegmentation/BreastSegmentationStudy-TF2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/SlicerIGT/aigt\n",
      "   4718350..bb585f9  master     -> origin/master\n"
     ]
    }
   ],
   "source": [
    "# Getting a clone of AIGT\n",
    "\n",
    "aigt_folder = Path('aigt')\n",
    "\n",
    "if aigt_folder.exists():\n",
    "    print(\"Updating aigt clone\")\n",
    "    !git -C aigt pull\n",
    "else:\n",
    "    print(\"Cloning aigt\")\n",
    "    !git clone -q https://github.com/SlicerIGT/aigt.git\n",
    "\n",
    "import aigt.Models.segmentation_unet as unet\n",
    "import aigt.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(local_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 has 387 ultrasounds and 387 segmentations\n",
      "Patient 1 has 79 ultrasounds and 79 segmentations\n",
      "Patient 2 has 360 ultrasounds and 360 segmentations\n",
      "Patient 3 has 453 ultrasounds and 453 segmentations\n",
      "Patient 4 has 349 ultrasounds and 349 segmentations\n",
      "Patient 5 has 289 ultrasounds and 289 segmentations\n",
      "Patient 6 has 477 ultrasounds and 477 segmentations\n",
      "Patient 7 has 332 ultrasounds and 332 segmentations\n",
      "Patient 8 has 446 ultrasounds and 446 segmentations\n",
      "Patient 9 has 172 ultrasounds and 172 segmentations\n",
      "Patient 10 has 355 ultrasounds and 355 segmentations\n",
      "Patient 11 has 523 ultrasounds and 523 segmentations\n"
     ]
    }
   ],
   "source": [
    "# Fetching Girder data\n",
    "girder_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "data_csv_file = \"CombinedSagittalCopy.csv\"\n",
    "\n",
    "from girder_api_key import girder_key\n",
    "ultrasound_arrays_by_patients, segmentation_arrays_by_patients =\\\n",
    "    aigt.utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key=girder_key)\n",
    "    \n",
    "n_patients = len(ultrasound_arrays_by_patients)\n",
    "\n",
    "for i in range(n_patients):\n",
    "    print(\"Patient {} has {} ultrasounds and {} segmentations\".format(\n",
    "        i, ultrasound_arrays_by_patients[i].shape[0], segmentation_arrays_by_patients[i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning 12 rounds of validation\n",
      "Validation on patients [0] in round 0\n",
      "Validation on patients [1] in round 1\n",
      "Validation on patients [2] in round 2\n",
      "Validation on patients [3] in round 3\n",
      "Validation on patients [4] in round 4\n",
      "Validation on patients [5] in round 5\n",
      "Validation on patients [6] in round 6\n",
      "Validation on patients [7] in round 7\n",
      "Validation on patients [8] in round 8\n",
      "Validation on patients [9] in round 9\n",
      "Validation on patients [10] in round 10\n",
      "Validation on patients [11] in round 11\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation rounds\n",
    "\n",
    "if np.max(validation_schedule_patient) > (n_patients - 1):\n",
    "    raise Exception(\"Patient ID cannot be greater than {}\".format(n_patients - 1))\n",
    "\n",
    "num_validation_rounds = len(validation_schedule_patient)\n",
    "print(\"Planning {} rounds of validation\".format(num_validation_rounds))\n",
    "for i in range(num_validation_rounds):\n",
    "    print(\"Validation on patients {} in round {}\".format(validation_schedule_patient[i], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2020-06-22_16-34-28\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    500\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     3.998e-05\n",
      "Batch size:          128\n",
      "Regularization rate: 0.0001\n",
      "\n",
      "Saving validation predictions in: C:\\Data\\SagittalSpineSegmentationStudy\\PredictionsValidation\n",
      "Saving models in:                 C:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\n",
      "\n",
      "*** Leave-one-out round # 0\n",
      "    Training on 3835 images, validating on 387 images...\n",
      "WARNING:tensorflow:From <ipython-input-18-f20c83a43406>:103: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "  Training time: 10:36:53.210166\n",
      "\n",
      "Total round time:  10:37:04.857997\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 1\n",
      "    Training on 4143 images, validating on 79 images...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for val_round_index in range(num_validation_rounds):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         ultrasound_arrays_by_patients[0].shape[1],\n",
    "         ultrasound_arrays_by_patients[0].shape[2],\n",
    "         ultrasound_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         segmentation_arrays_by_patients[0].shape[1],\n",
    "         segmentation_arrays_by_patients[0].shape[2],\n",
    "         segmentation_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    val_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         ultrasound_arrays_by_patients[0].shape[1],\n",
    "         ultrasound_arrays_by_patients[0].shape[2],\n",
    "         ultrasound_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    val_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         segmentation_arrays_by_patients[0].shape[1],\n",
    "         segmentation_arrays_by_patients[0].shape[2],\n",
    "         segmentation_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    for patient_index in range(n_patients):\n",
    "        if patient_index not in validation_schedule_patient[val_round_index]:\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                    ultrasound_arrays_by_patients[patient_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                      segmentation_arrays_by_patients[patient_index]))\n",
    "        else:\n",
    "            val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                 ultrasound_arrays_by_patients[patient_index]))\n",
    "            val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                   segmentation_arrays_by_patients[patient_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.shape[0]\n",
    "    n_val = val_ultrasound_data.shape[0]\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(val_round_index))\n",
    "    print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # model.summary()\n",
    "        \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    if n_val > 0:\n",
    "        training_log = model.fit_generator(\n",
    "            training_generator,\n",
    "            validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "            epochs=num_epochs,\n",
    "            verbose=0)\n",
    "    else:\n",
    "        training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "    \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    if n_val > 0:\n",
    "        axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    if n_val > 0:\n",
    "        axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(val_round_index) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    if n_val > 0:\n",
    "        y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "        # Saving predictions for further evaluation\n",
    "\n",
    "        val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "        val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "        np.save(val_prediction_fullname, y_pred_val)\n",
    "\n",
    "        # Validation results\n",
    "\n",
    "        vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "            roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "            y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "        val_aurocs[val_round_index]          = vali_area\n",
    "        val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    if i in val_best_metrics.keys():\n",
    "        results_df.loc[i] = [\n",
    "            val_aurocs[i],\n",
    "            val_best_thresholds[i],\n",
    "            val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "        ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last ROC curve for visual verification that we catch the optimal point\n",
    "\n",
    "n = len(roc_thresholds)\n",
    "\n",
    "roc_x = np.zeros(n)\n",
    "roc_y = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    roc_x[i] = vali_metrics_dicts[i][evaluation_metrics.FALSE_POSITIVE_RATE]\n",
    "    roc_y[i] = vali_metrics_dicts[i][evaluation_metrics.SENSITIVITY]\n",
    "    # print(\"Threshold = {0:4.2f}  False pos rate = {1:4.2f}  Sensitivity = {2:4.2f}\"\n",
    "    #       .format(roc_thresholds[i], roc_x[i], roc_y[i]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.plot(roc_x, roc_y, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "num_vali = val_ultrasound_data.shape[0]\n",
    "num_show = 3\n",
    "if num_vali < num_show:\n",
    "    num_show = 0\n",
    "num_col = 4\n",
    "    \n",
    "indices = [i for i in range(num_vali)]\n",
    "sample_indices = sample(indices, num_show)\n",
    "sample_indices = [105, 195, 391]\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Uncomment for comparing the same images\n",
    "# sample_indices = [105, 195, 391, 133, 142]\n",
    "\n",
    "fig = plt.figure(figsize=(18, num_show*5))\n",
    "for i in range(num_show):\n",
    "    a0 = fig.add_subplot(num_show, num_col, i*num_col+1)\n",
    "    img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[i], :, :, 0].astype(np.float32)))\n",
    "    a0.set_title(\"Ultrasound #{}\".format(sample_indices[i]))\n",
    "    a1 = fig.add_subplot(num_show, num_col, i*num_col+2)\n",
    "    img1 = a1.imshow(np.flipud(val_segmentation_data_onehot[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a1.set_title(\"Segmentation #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "    a2 = fig.add_subplot(num_show, num_col, i*num_col+3)\n",
    "    img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a2.set_title(\"Prediction #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img2, fraction=0.046, pad=0.04)\n",
    "    a3 = fig.add_subplot(num_show, num_col, i*num_col+4)\n",
    "    img3 = a3.imshow((np.flipud(y_pred_val[sample_indices[i], :, :, 1]) > threshold), vmin=0.0, vmax=1.0)\n",
    "    c = fig.colorbar(img3, fraction=0.046, pad=0.04)\n",
    "    a3.set_title(\"Thresholded #{}\".format(sample_indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
