{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained tensorflow model\n",
    "\n",
    "model_fullname = r\"C:\\Users\\perkl\\Documents\\AIGT\\aigt\\SavedModels\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-1_2020-05-12_17-19-33.h5\"\n",
    "\n",
    "# Input ultrasound sequence names\n",
    "\n",
    "input_browser_name = r\"LandmarkingScan\"\n",
    "input_image_name = r\"Image_Image\"\n",
    "\n",
    "# Output will be saved using these names\n",
    "\n",
    "output_browser_name = r\"BonePredictionBrowser\"\n",
    "output_sequence_name = r\"PredictionSequence\"\n",
    "output_image_name = r\"PredictionImage\"\n",
    "\n",
    "# Optionally save output to numpy arrays\n",
    "\n",
    "array_output = False\n",
    "array_folder_name = r\"Temp\"\n",
    "array_segmentation_name = r\"segmentation\"\n",
    "array_ultrasound_name = r\"ultrasound\"\n",
    "\n",
    "# Image processing parameters\n",
    "\n",
    "# Erases the side of prediction images. 1.0 means the whole prediction is erased.\n",
    "# Background should be the first component (i.e. y[:,:,:,0]) in the prediction output array.\n",
    "\n",
    "clip_side_ratio = 0.3\n",
    "apply_logarithmic_transformation = True\n",
    "logarithmic_transformation_decimals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from local_vars import root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: girder_client in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: diskcache in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from girder_client) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.4.2 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from girder_client) (2.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from girder_client) (1.14.0)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from girder_client) (7.1.2)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from girder_client) (0.9.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from requests>=2.4.2->girder_client) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from requests>=2.4.2->girder_client) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from requests>=2.4.2->girder_client) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\perkl\\appdata\\local\\na-mic\\slicer 4.11.0-2020-05-10\\lib\\python\\lib\\site-packages (from requests>=2.4.2->girder_client) (2.9)\n",
      "WARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\perkl\\AppData\\Local\\NA-MIC\\Slicer 4.11.0-2020-05-10\\bin\\python-real.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# The aigt repository needs to be cloned in this folder\n",
    "import aigt.Models.segmentation_unet as unet\n",
    "import aigt.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagittal_spine_segmentation_unet as unet\n",
    "# wcce = unet.weighted_categorical_crossentropy([0.05, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\perkl\\Documents\\AIGT\\aigt\\SavedModels\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-1_2020-05-12_17-19-33.h5\n"
     ]
    }
   ],
   "source": [
    "# Check if keras model file exists. Abort if not found. Load model otherwise.\n",
    "\n",
    "if not os.path.exists(model_fullname):\n",
    "    raise Exception(\"Could not find model: \" + model_fullname)\n",
    "\n",
    "print(\"Loading model from: \" + model_fullname)\n",
    "\n",
    "if array_output:\n",
    "    array_output_fullpath = os.path.join(root_folder, array_folder_name)\n",
    "    array_segmentation_fullname = os.path.join(array_output_fullpath, array_segmentation_name)\n",
    "    array_ultrasound_fullname = os.path.join(array_output_fullpath, array_ultrasound_name)\n",
    "    if not os.path.exists(array_output_fullpath):\n",
    "        os.mkdir(array_output_fullpath)\n",
    "        print(\"Folder created: {}\".format(array_output_fullpath))\n",
    "    print(\"Will save segmentation output to {}\".format(array_segmentation_fullname))\n",
    "    print(\"Will save ultrasound output to   {}\".format(array_ultrasound_fullname))\n",
    "\n",
    "model = tf.keras.models.load_model(model_fullname, compile=False)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check input. Abort if browser or image doesn't exist.\n",
    "\n",
    "input_browser_node = slicer.util.getFirstNodeByName(input_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "input_image_node = slicer.util.getFirstNodeByName(input_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "\n",
    "if input_browser_node is None:\n",
    "    logging.error(\"Could not find input browser node: {}\".format(input_browser_node))\n",
    "    raise\n",
    "\n",
    "if input_image_node is None:\n",
    "    logging.error(\"Could not find input image node: {}\".format(input_image_name))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output image and browser for segmentation output.\n",
    "\n",
    "output_browser_node = slicer.util.getFirstNodeByName(output_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "if output_browser_node is None:\n",
    "    output_browser_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceBrowserNode', output_browser_name)\n",
    "\n",
    "output_sequence_node = slicer.util.getFirstNodeByName(output_sequence_name, className=\"vtkMRMLSequenceNode\")\n",
    "if output_sequence_node is None:\n",
    "    output_sequence_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode', output_sequence_name)\n",
    "    output_browser_node.AddSynchronizedSequenceNode(output_sequence_node)\n",
    "\n",
    "output_image_node = slicer.util.getFirstNodeByName(output_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "if output_image_node is None:\n",
    "    volumes_logic = slicer.modules.volumes.logic()\n",
    "    output_image_node = volumes_logic.CloneVolume(slicer.mrmlScene, input_image_node, output_image_name)\n",
    "    browser_logic = slicer.modules.sequences.logic()\n",
    "    browser_logic.AddSynchronizedNode(output_sequence_node, output_image_node, output_browser_node)\n",
    "\n",
    "output_browser_node.SetRecording(output_sequence_node, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all input sequences to the output browser for being able to conveniently replay everything\n",
    "\n",
    "proxy_collection = vtk.vtkCollection()\n",
    "input_browser_node.GetAllProxyNodes(proxy_collection)\n",
    "\n",
    "for i in range(proxy_collection.GetNumberOfItems()):\n",
    "    proxy_node = proxy_collection.GetItemAsObject(i)\n",
    "    output_sequence = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode')\n",
    "    browser_logic.AddSynchronizedNode(output_sequence, proxy_node, output_browser_node)\n",
    "    output_browser_node.SetRecording(output_sequence, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will segment 1164 images\n"
     ]
    }
   ],
   "source": [
    "# Iterate input sequence, compute segmentation for each frame, record output sequence.\n",
    "\n",
    "num_items = input_browser_node.GetNumberOfItems()\n",
    "n = num_items\n",
    "input_browser_node.SelectFirstItem()\n",
    "\n",
    "input_array = slicer.util.array(input_image_node.GetID())\n",
    "slicer_to_model_scaling = model.layers[0].input_shape[0][1] / input_array.shape[1]\n",
    "model_to_slicer_scaling = input_array.shape[1] / model.layers[0].input_shape[0][1]\n",
    "\n",
    "print(\"Will segment {} images\".format(n))\n",
    "\n",
    "if array_output:\n",
    "    array_output_ultrasound = np.zeros((n, input_array.shape[1], input_array.shape[1]))\n",
    "    array_output_segmentation = np.zeros((n, input_array.shape[1], input_array.shape[1]), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will mask 19 columns on both sides\n"
     ]
    }
   ],
   "source": [
    "model_output_size = model.layers[-1].output_shape[1]\n",
    "num_output_components = model.layers[-1].output_shape[3]\n",
    "\n",
    "mask_model = np.ones([model_output_size, model_output_size])\n",
    "mask_model_background = np.zeros([model_output_size, model_output_size])\n",
    "\n",
    "columns_to_mask = int(model_output_size / 2 * clip_side_ratio)\n",
    "print(\"Will mask {} columns on both sides\".format(columns_to_mask))\n",
    "\n",
    "mask_model[:,:columns_to_mask] = 0\n",
    "mask_model[:,-columns_to_mask:] = 0\n",
    "mask_model_background[:,:columns_to_mask] = 1\n",
    "mask_model_background[:,-columns_to_mask:] = 1\n",
    "\n",
    "# Display mask\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('WXAgg')\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.imshow(mask_model[:,:])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing started at: 14-29-39\n",
      "Processing finished at: 14-32-07\n"
     ]
    }
   ],
   "source": [
    "start_timestamp = datetime.datetime.now()\n",
    "print(\"Processing started at: {}\".format(start_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    # if i > 10:  # todo Just for debugging\n",
    "    #     break\n",
    "    input_array = slicer.util.array(input_image_node.GetID())\n",
    "    \n",
    "    if array_output:\n",
    "        array_output_ultrasound[i, :, :] = input_array[0, :, :]\n",
    "    \n",
    "    resized_input_array = scipy.ndimage.zoom(input_array[0,:,:], slicer_to_model_scaling)\n",
    "    resized_input_array = np.flip(resized_input_array, axis=0)\n",
    "    resized_input_array = resized_input_array / resized_input_array.max()  # Scaling intensity to 0-1\n",
    "    resized_input_array = np.expand_dims(resized_input_array, axis=0)\n",
    "    resized_input_array = np.expand_dims(resized_input_array, axis=3)\n",
    "    y = model.predict(resized_input_array)\n",
    "    if apply_logarithmic_transformation:\n",
    "        e = logarithmic_transformation_decimals\n",
    "        y = np.log10(np.clip(y, 10**(-e), 1.0)*(10**e))/e\n",
    "    y[0,:,:,:] = np.flip(y[0,:,:,:], axis=0)\n",
    "    \n",
    "    for component in range(1, num_output_components):\n",
    "        y[0,:,:,component] = y[0,:,:,component] * mask_model[:,:]\n",
    "    y[0,:,:,0] = np.maximum(y[0,:,:,0], mask_model_background)\n",
    "    \n",
    "    upscaled_output_array = scipy.ndimage.zoom(y[0,:,:,1], model_to_slicer_scaling)\n",
    "    upscaled_output_array = upscaled_output_array * 255\n",
    "    upscaled_output_array = np.clip(upscaled_output_array, 0, 255)\n",
    "    \n",
    "    if array_output:\n",
    "        array_output_segmentation[i, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "    \n",
    "    # output_array = slicer.util.array(output_image_node.GetID())\n",
    "    # output_array[0, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "    \n",
    "    slicer.util.updateVolumeFromArray(output_image_node, upscaled_output_array.astype(np.uint8)[np.newaxis, ...])\n",
    "    \n",
    "    output_browser_node.SaveProxyNodesState()\n",
    "    input_browser_node.SelectNextItem()\n",
    "    \n",
    "    # If Slicer crashes during processing, try commenting this following line out and run this notebook again.\n",
    "    slicer.app.processEvents()\n",
    "\n",
    "\n",
    "stop_timestamp = datetime.datetime.now()\n",
    "print(\"Processing finished at: {}\".format(stop_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "if array_output:\n",
    "    np.save(array_ultrasound_fullname, array_output_ultrasound)\n",
    "    np.save(array_segmentation_fullname, array_output_segmentation)\n",
    "    print(\"Saved {}\".format(array_ultrasound_fullname))\n",
    "    print(\"Saved {}\".format(array_segmentation_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1164 frames in 148.30 seconds\n",
      "FPS = 7.85\n"
     ]
    }
   ],
   "source": [
    "time_seconds = (stop_timestamp - start_timestamp).total_seconds()\n",
    "print(\"Processed {} frames in {:.2f} seconds\".format(n, time_seconds))\n",
    "print(\"FPS = {:.2f}\".format(n / time_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Slicer 4.11",
   "language": "python",
   "name": "slicer-4.11"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
