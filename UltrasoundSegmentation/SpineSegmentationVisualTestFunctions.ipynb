{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import JupyterNotebooksLib as slicernb\n",
    "import numpy as np\n",
    "\n",
    "this_notebook_name = \"SpineSegmentationVisualTestFunctions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-07-07_14-08-39\n"
     ]
    }
   ],
   "source": [
    "# place paths to scenes to test here\n",
    "scenes_to_reconstruct = [\n",
    "    r\"c:\\Users\\perkl\\Documents\\AIGT\\OneDrive_1_5-12-2020\\317_Ax_Ready.mrb\",\n",
    "    r\"c:\\Users\\perkl\\Documents\\AIGT\\SpineUsOutput\\39_Sa_Ready.mrb\"\n",
    "]\n",
    "\n",
    "# all paths to models to study\n",
    "models = [\n",
    "    r\"c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-4_2020-06-23_19-47-30.h5\",\n",
    "    r\"c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-7_2020-06-28_22-31-54.h5\"\n",
    "]\n",
    "\n",
    "# folder to temporarily store images\n",
    "image_output_path = 'C:/Users/perkl/Documents/AIGT/PNGs/Image_{}.png'\n",
    "\n",
    "images_to_plot = np.array([])\n",
    "\n",
    "# Input ultrasound sequence names\n",
    "\n",
    "input_browser_name = r\"LandmarkingScan\"\n",
    "input_image_name = r\"Image_Image\"\n",
    "\n",
    "# Output will be saved using these names\n",
    "\n",
    "output_browser_name = r\"BonePredictionBrowser\"\n",
    "output_sequence_name = r\"PredictionSequence\"\n",
    "output_image_name = r\"PredictionImage\"\n",
    "\n",
    "# Optionally save output to numpy arrays\n",
    "\n",
    "array_output = False\n",
    "array_folder_name = r\"Temp\"\n",
    "array_segmentation_name = r\"segmentation\"\n",
    "array_ultrasound_name = r\"ultrasound\"\n",
    "\n",
    "# Image processing parameters\n",
    "\n",
    "# Erases the side of prediction images. 1.0 means the whole prediction is erased.\n",
    "# Background should be the first component (i.e. y[:,:,:,0]) in the prediction output array.\n",
    "\n",
    "clip_side_ratio = 0.3\n",
    "apply_logarithmic_transformation = True\n",
    "logarithmic_transformation_decimals = 4\n",
    "\n",
    "# notebook output path\n",
    "notebooks_save_path = r\"c:\\Data\\SagittalSpineSegmentationStudy\\SavedNotebooks\"\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import qt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# from local_vars import root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(scene):\n",
    "    # loading scene\n",
    "    slicer.mrmlScene.Clear()\n",
    "    try:\n",
    "        slicer.util.loadScene(scene)\n",
    "    except:\n",
    "        # NOTE: for some reason loading a scene throws an error every time, but laods the scene just fine\n",
    "        print('Error thrown. Continuing.')\n",
    "        \n",
    "    # changing transform hierarchy\n",
    "    image_image = slicer.util.getFirstNodeByName(input_image_name)\n",
    "    imageToTransd = slicer.util.getFirstNodeByName(\"ImageToTransd\")\n",
    "\n",
    "    image_image.SetAndObserveTransformNodeID(None)\n",
    "    image_image.SetAndObserveTransformNodeID(imageToTransd.GetID())\n",
    "    \n",
    "    \n",
    "    slicer.app.layoutManager().setLayout(slicer.vtkMRMLLayoutNode.SlicerLayoutOneUp3DView)\n",
    "    \n",
    "    #hide skeleton model\n",
    "    skeleton = slicer.util.getFirstNodeByName(\"SkeletonModel\")\n",
    "    if skeleton is not None:\n",
    "        skeleton.SetDisplayVisibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_fullname):\n",
    "    # Check if keras model file exists. Abort if not found. Load model otherwise.\n",
    "\n",
    "    if not os.path.exists(model_fullname):\n",
    "        raise Exception(\"Could not find model: \" + model_fullname)\n",
    "\n",
    "    print(\"Loading model from: \" + model_fullname)\n",
    "\n",
    "    if array_output:\n",
    "        array_output_fullpath = os.path.join(root_folder, array_folder_name)\n",
    "        array_segmentation_fullname = os.path.join(array_output_fullpath, array_segmentation_name)\n",
    "        array_ultrasound_fullname = os.path.join(array_output_fullpath, array_ultrasound_name)\n",
    "        if not os.path.exists(array_output_fullpath):\n",
    "            os.mkdir(array_output_fullpath)\n",
    "            print(\"Folder created: {}\".format(array_output_fullpath))\n",
    "        print(\"Will save segmentation output to {}\".format(array_segmentation_fullname))\n",
    "        print(\"Will save ultrasound output to   {}\".format(array_ultrasound_fullname))\n",
    "\n",
    "    model = tf.keras.models.load_model(model_fullname, compile=False)\n",
    "    return model\n",
    "\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(model):\n",
    "    # Check input. Abort if browser or image doesn't exist.\n",
    "\n",
    "    input_browser_node = slicer.util.getFirstNodeByName(input_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "    input_image_node = slicer.util.getFirstNodeByName(input_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "\n",
    "    if input_browser_node is None:\n",
    "        logging.error(\"Could not find input browser node: {}\".format(input_browser_node))\n",
    "        raise\n",
    "\n",
    "    if input_image_node is None:\n",
    "        logging.error(\"Could not find input image node: {}\".format(input_image_name))\n",
    "        raise\n",
    "\n",
    "    # Create output image and browser for segmentation output.\n",
    "\n",
    "    output_browser_node = slicer.util.getFirstNodeByName(output_browser_name, className='vtkMRMLSequenceBrowserNode')\n",
    "    if output_browser_node is None:\n",
    "        output_browser_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceBrowserNode', output_browser_name)\n",
    "\n",
    "    output_sequence_node = slicer.util.getFirstNodeByName(output_sequence_name, className=\"vtkMRMLSequenceNode\")\n",
    "    if output_sequence_node is None:\n",
    "        output_sequence_node = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode', output_sequence_name)\n",
    "        output_browser_node.AddSynchronizedSequenceNode(output_sequence_node)\n",
    "\n",
    "    output_image_node = slicer.util.getFirstNodeByName(output_image_name, className=\"vtkMRMLScalarVolumeNode\")\n",
    "    # browser_logic = slicer.modules.sequences.logic()\n",
    "    if output_image_node is None:\n",
    "        volumes_logic = slicer.modules.volumes.logic()\n",
    "        output_image_node = volumes_logic.CloneVolume(slicer.mrmlScene, input_image_node, output_image_name)\n",
    "        browser_logic = slicer.modules.sequences.logic()\n",
    "        browser_logic.AddSynchronizedNode(output_sequence_node, output_image_node, output_browser_node)\n",
    "\n",
    "    output_browser_node.SetRecording(output_sequence_node, True)\n",
    "\n",
    "    # Add all input sequences to the output browser for being able to conveniently replay everything\n",
    "\n",
    "    proxy_collection = vtk.vtkCollection()\n",
    "    input_browser_node.GetAllProxyNodes(proxy_collection)\n",
    "\n",
    "    for i in range(proxy_collection.GetNumberOfItems()):\n",
    "        proxy_node = proxy_collection.GetItemAsObject(i)\n",
    "        output_sequence = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSequenceNode')\n",
    "        browser_logic.AddSynchronizedNode(output_sequence, proxy_node, output_browser_node)\n",
    "        output_browser_node.SetRecording(output_sequence, True)\n",
    "\n",
    "    # Iterate input sequence, compute segmentation for each frame, record output sequence.\n",
    "\n",
    "    num_items = input_browser_node.GetNumberOfItems()\n",
    "    n = num_items\n",
    "    input_browser_node.SelectFirstItem()\n",
    "\n",
    "    input_array = slicer.util.array(input_image_node.GetID())\n",
    "    slicer_to_model_scaling = model.layers[0].input_shape[0][1] / input_array.shape[1]\n",
    "    model_to_slicer_scaling = input_array.shape[1] / model.layers[0].input_shape[0][1]\n",
    "\n",
    "    print(\"Will segment {} images\".format(n))\n",
    "\n",
    "    if array_output:\n",
    "        array_output_ultrasound = np.zeros((n, input_array.shape[1], input_array.shape[1]))\n",
    "        array_output_segmentation = np.zeros((n, input_array.shape[1], input_array.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    model_output_size = model.layers[-1].output_shape[1]\n",
    "    num_output_components = model.layers[-1].output_shape[3]\n",
    "\n",
    "    mask_model = np.ones([model_output_size, model_output_size])\n",
    "    mask_model_background = np.zeros([model_output_size, model_output_size])\n",
    "\n",
    "    columns_to_mask = int(model_output_size / 2 * clip_side_ratio)\n",
    "    print(\"Will mask {} columns on both sides\".format(columns_to_mask))\n",
    "\n",
    "    mask_model[:,:columns_to_mask] = 0\n",
    "    mask_model[:,-columns_to_mask:] = 0\n",
    "    mask_model_background[:,:columns_to_mask] = 1\n",
    "    mask_model_background[:,-columns_to_mask:] = 1\n",
    "\n",
    "    # Display mask\n",
    "\n",
    "    # import matplotlib\n",
    "    # matplotlib.use('WXAgg')\n",
    "\n",
    "    # from matplotlib import pyplot as plt\n",
    "\n",
    "    # plt.imshow(mask_model[:,:])\n",
    "    # plt.show()\n",
    "\n",
    "    start_timestamp = datetime.datetime.now()\n",
    "    print(\"Processing started at: {}\".format(start_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        # if i > 10:  # todo Just for debugging\n",
    "        #     break\n",
    "        input_array = slicer.util.array(input_image_node.GetID())\n",
    "\n",
    "        if array_output:\n",
    "            array_output_ultrasound[i, :, :] = input_array[0, :, :]\n",
    "\n",
    "        resized_input_array = scipy.ndimage.zoom(input_array[0,:,:], slicer_to_model_scaling)\n",
    "        resized_input_array = np.flip(resized_input_array, axis=0)\n",
    "        resized_input_array = resized_input_array / resized_input_array.max()  # Scaling intensity to 0-1\n",
    "        resized_input_array = np.expand_dims(resized_input_array, axis=0)\n",
    "        resized_input_array = np.expand_dims(resized_input_array, axis=3)\n",
    "        y = model.predict(resized_input_array)\n",
    "        if apply_logarithmic_transformation:\n",
    "            e = logarithmic_transformation_decimals\n",
    "            y = np.log10(np.clip(y, 10**(-e), 1.0)*(10**e))/e\n",
    "        y[0,:,:,:] = np.flip(y[0,:,:,:], axis=0)\n",
    "\n",
    "        for component in range(1, num_output_components):\n",
    "            y[0,:,:,component] = y[0,:,:,component] * mask_model[:,:]\n",
    "        y[0,:,:,0] = np.maximum(y[0,:,:,0], mask_model_background)\n",
    "\n",
    "        upscaled_output_array = scipy.ndimage.zoom(y[0,:,:,1], model_to_slicer_scaling)\n",
    "        upscaled_output_array = upscaled_output_array * 255\n",
    "        upscaled_output_array = np.clip(upscaled_output_array, 0, 255)\n",
    "\n",
    "        if array_output:\n",
    "            array_output_segmentation[i, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "\n",
    "        # output_array = slicer.util.array(output_image_node.GetID())\n",
    "        # output_array[0, :, :] = upscaled_output_array[:, :].astype(np.uint8)\n",
    "\n",
    "        slicer.util.updateVolumeFromArray(output_image_node, upscaled_output_array.astype(np.uint8)[np.newaxis, ...])\n",
    "\n",
    "        output_browser_node.SaveProxyNodesState()\n",
    "        input_browser_node.SelectNextItem()\n",
    "\n",
    "        # If Slicer crashes during processing, try commenting this following line out and run this notebook again.\n",
    "        slicer.app.processEvents()\n",
    "\n",
    "\n",
    "    stop_timestamp = datetime.datetime.now()\n",
    "    print(\"Processing finished at: {}\".format(stop_timestamp.strftime('%H-%M-%S')))\n",
    "\n",
    "\n",
    "    if array_output:\n",
    "        np.save(array_ultrasound_fullname, array_output_ultrasound)\n",
    "        np.save(array_segmentation_fullname, array_output_segmentation)\n",
    "        print(\"Saved {}\".format(array_ultrasound_fullname))\n",
    "        print(\"Saved {}\".format(array_segmentation_fullname))\n",
    "\n",
    "    time_seconds = (stop_timestamp - start_timestamp).total_seconds()\n",
    "    print(\"Processed {} frames in {:.2f} seconds\".format(n, time_seconds))\n",
    "    print(\"FPS = {:.2f}\".format(n / time_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_volume():\n",
    "    # Find input volume (image) for volume reconstruction\n",
    "\n",
    "    predictionVolume = slicer.mrmlScene.GetFirstNodeByName(\"PredictionImage\")\n",
    "    if predictionVolume is None:\n",
    "        raise Exception(\"PredictionImage not found in Slicer scene\")\n",
    "\n",
    "    # Create output volume node\n",
    "\n",
    "    reconstructedVolume = slicer.mrmlScene.GetFirstNodeByName(\"AiVolume\")\n",
    "    if reconstructedVolume is None:\n",
    "        reconstructedVolume = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLScalarVolumeNode\")\n",
    "        reconstructedVolume.SetName(\"AiVolume\")\n",
    "\n",
    "    inputBrowserNode = slicer.mrmlScene.GetFirstNodeByName(\"BonePredictionBrowser\")\n",
    "    if inputBrowserNode is None:\n",
    "        raise Exception(\"BonePredictionBrowser missing\")\n",
    "\n",
    "    # Prepare volume reconstructor node\n",
    "\n",
    "    volumeReconstructor = slicer.mrmlScene.GetFirstNodeByName(\"AiVolumeReconstructor\")\n",
    "    if volumeReconstructor is None:\n",
    "        volumeReconstructor = slicer.vtkMRMLVolumeReconstructionNode()\n",
    "        volumeReconstructor.SetName(\"AiVolumeReconstructor\")\n",
    "        volumeReconstructor.SetLiveVolumeReconstruction(False)\n",
    "        volumeReconstructor.SetOptimizationMode(slicer.vtkMRMLVolumeReconstructionNode.FULL_OPTIMIZATION)\n",
    "        volumeReconstructor.SetCompoundingMode(slicer.vtkMRMLVolumeReconstructionNode.MAXIMUM_COMPOUNDING_MODE)\n",
    "        volumeReconstructor.SetInterpolationMode(slicer.vtkMRMLVolumeReconstructionNode.LINEAR_INTERPOLATION)\n",
    "        slicer.mrmlScene.AddNode(volumeReconstructor)\n",
    "\n",
    "    volumeReconstructor.SetAndObserveInputSequenceBrowserNode(inputBrowserNode)\n",
    "    volumeReconstructor.SetAndObserveOutputVolumeNode(reconstructedVolume)\n",
    "    volumeReconstructor.SetAndObserveInputVolumeNode(predictionVolume)\n",
    "\n",
    "    volumeReconstructionLogic = slicer.modules.volumereconstruction.logic()\n",
    "\n",
    "    # Volume reconstruction\n",
    "\n",
    "    volumeReconstructionLogic.ReconstructVolumeFromSequence(volumeReconstructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_volume():\n",
    "    # Volume rendering\n",
    "\n",
    "    # find input volume\n",
    "    aivolumeNode = slicer.mrmlScene.GetFirstNodeByName(\"AiVolume\")\n",
    "    if aivolumeNode is None:\n",
    "        raise Exception(\"AiVolume node was never constructed\")\n",
    "\n",
    "    # find or build ROI\n",
    "    annotationROINode = slicer.mrmlScene.GetFirstNodeByName(\"AnnotationROI\")\n",
    "    if annotationROINode is None:\n",
    "        annotationROINode = slicer.vtkMRMLAnnotationROINode()\n",
    "        annotationROINode.SetName(\"AnnotationROI\")\n",
    "        slicer.mrmlScene.AddNode(annotationROINode)\n",
    "        annotationROINode.SetDisplayVisibility(False)\n",
    "\n",
    "    # find or build volume property\n",
    "    propertyPresetNode = slicer.mrmlScene.GetFirstNodeByName(\"volMR-Default\")\n",
    "    if propertyPresetNode is None:\n",
    "        propertyPresetNode = slicer.vtkMRMLVolumePropertyNode()\n",
    "        propertyPresetNode.SetName(\"volMR-Default\")\n",
    "        volumeRenderingLogic = slicer.modules.volumerendering.logic()\n",
    "        propertyPresetNode.Copy(volumeRenderingLogic.GetPresetByName('MR-Default'))\n",
    "        slicer.mrmlScene.AddNode(propertyPresetNode)\n",
    "\n",
    "    # build 3D renderer\n",
    "    volumeRenderingLogic = slicer.modules.volumerendering.logic()\n",
    "    displayNode = volumeRenderingLogic.GetFirstVolumeRenderingDisplayNode(aivolumeNode)\n",
    "    if displayNode is None:\n",
    "        displayNode = slicer.vtkMRMLGPURayCastVolumeRenderingDisplayNode()\n",
    "        displayNode.SetName(\"AiVolumeRenderer\")\n",
    "        slicer.mrmlScene.AddNode(displayNode)\n",
    "\n",
    "        aivolumeNode.AddAndObserveDisplayNodeID(displayNode.GetID())\n",
    "\n",
    "        displayNode.SetAndObserveVolumePropertyNodeID(propertyPresetNode.GetID())\n",
    "        displayNode.SetAndObserveROINodeID(annotationROINode.GetID())\n",
    "\n",
    "    displayNode.SetVisibility(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error thrown. Continuing.\n",
      "Loading model from: c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-4_2020-06-23_19-47-30.h5\n",
      "Will segment 1164 images\n",
      "Will mask 19 columns on both sides\n",
      "Processing started at: 14-08-45\n",
      "Processing finished at: 14-09-59\n",
      "Processed 1164 frames in 74.00 seconds\n",
      "FPS = 15.73\n",
      "Loading model from: c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-4_2020-06-23_19-47-30.h5\n",
      "Will segment 3400 images\n",
      "Will mask 19 columns on both sides\n",
      "Processing started at: 14-10-39\n",
      "Processing finished at: 14-14-08\n",
      "Processed 3400 frames in 208.17 seconds\n",
      "FPS = 16.33\n",
      "Error thrown. Continuing.\n",
      "Loading model from: c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-7_2020-06-28_22-31-54.h5\n",
      "Will segment 1164 images\n",
      "Will mask 19 columns on both sides\n",
      "Processing started at: 14-15-32\n",
      "Processing finished at: 14-16-46\n",
      "Processed 1164 frames in 73.59 seconds\n",
      "FPS = 15.82\n",
      "Loading model from: c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\\SagittalSpineSegmentationStudy-TF2_model-7_2020-06-28_22-31-54.h5\n",
      "Will segment 3400 images\n",
      "Will mask 19 columns on both sides\n",
      "Processing started at: 14-17-27\n",
      "Processing finished at: 14-20-58\n",
      "Processed 3400 frames in 210.59 seconds\n",
      "FPS = 16.15\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for model in models:\n",
    "    for scene in scenes_to_reconstruct:\n",
    "        setup(scene)\n",
    "\n",
    "        segment(load_model(model))\n",
    "\n",
    "        reconstruct_volume()\n",
    "        render_volume()\n",
    "\n",
    "        from time import sleep\n",
    "        sleep(1)\n",
    "\n",
    "        full_image_path = image_output_path.format(str(count))\n",
    "        count += 1\n",
    "        images_to_plot = np.append(images_to_plot, full_image_path)\n",
    "\n",
    "        renderWindow = slicer.app.layoutManager().threeDWidget(0).threeDView().renderWindow()\n",
    "        renderWindow.SetAlphaBitPlanes(1)\n",
    "        wti = vtk.vtkWindowToImageFilter()\n",
    "        wti.SetInputBufferTypeToRGBA()\n",
    "        wti.SetInput(renderWindow)\n",
    "        writer = vtk.vtkPNGWriter()\n",
    "        writer.SetFileName(full_image_path)\n",
    "        writer.SetInputConnection(wti.GetOutputPort())\n",
    "        writer.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block; width: 884px; vertical-align: top; text-align: center;\"><h4 style=\"font-size: 12px\">0</h4><h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 90%; word-wrap: break-word; white-space: normal;\">C:/Users/perkl/Documents/AIGT/PNGs/Image_0.png</h4><img src=\"C:/Users/perkl/Documents/AIGT/PNGs/Image_0.png\" style=\"margin: 1px; width: 864px; border: 2px solid #ddd;\"/></div><div style=\"display: inline-block; width: 884px; vertical-align: top; text-align: center;\"><h4 style=\"font-size: 12px\">1</h4><h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 90%; word-wrap: break-word; white-space: normal;\">C:/Users/perkl/Documents/AIGT/PNGs/Image_1.png</h4><img src=\"C:/Users/perkl/Documents/AIGT/PNGs/Image_1.png\" style=\"margin: 1px; width: 864px; border: 2px solid #ddd;\"/></div><div style=\"display: inline-block; width: 884px; vertical-align: top; text-align: center;\"><h4 style=\"font-size: 12px\">2</h4><h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 90%; word-wrap: break-word; white-space: normal;\">C:/Users/perkl/Documents/AIGT/PNGs/Image_2.png</h4><img src=\"C:/Users/perkl/Documents/AIGT/PNGs/Image_2.png\" style=\"margin: 1px; width: 864px; border: 2px solid #ddd;\"/></div><div style=\"display: inline-block; width: 884px; vertical-align: top; text-align: center;\"><h4 style=\"font-size: 12px\">3</h4><h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 90%; word-wrap: break-word; white-space: normal;\">C:/Users/perkl/Documents/AIGT/PNGs/Image_3.png</h4><img src=\"C:/Users/perkl/Documents/AIGT/PNGs/Image_3.png\" style=\"margin: 1px; width: 864px; border: 2px solid #ddd;\"/></div>"
      ],
      "text/plain": [
       "<display.HTML object at 0x000001B0A5AD93B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyplot\n",
    "\n",
    "ipyplot.plot_images(images_to_plot, img_width=864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require([\"base/js/namespace\"],function(Jupyter) {\n",
       "    Jupyter.notebook.save_checkpoint();\n",
       "});\n"
      ],
      "text/plain": [
       "<display.Javascript object at 0x000001B0A5AD9308>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: c:\\Data\\SagittalSpineSegmentationStudy\\SavedNotebooks\\SpineSegmentationVisualTestFunctions_2020-07-07_14-08-39.html\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "import json\n",
    "\n",
    "notebook_path = slicernb.notebookPath()\n",
    "\n",
    "with open(notebook_path, mode=\"r\") as f:\n",
    "    file_json = json.load(f)\n",
    "    \n",
    "notebook_content = nbformat.reads(json.dumps(file_json), as_version=4)\n",
    "\n",
    "html_exporter = HTMLExporter()\n",
    "(body, resources) = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "this_notebook_name = os.path.splitext(os.path.basename(notebook_path))[0]\n",
    "save_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullpath = os.path.join(notebooks_save_path, save_file_name)\n",
    "\n",
    "f = open(notebook_fullpath, 'wb')\n",
    "f.write(body.encode())\n",
    "f.close()\n",
    "\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullpath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Slicer 4.11",
   "language": "python",
   "name": "slicer-4.11"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
